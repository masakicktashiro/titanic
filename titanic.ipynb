{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData Dictionary\\nVariable\\nDefinition\\nKey\\nsurvival\\nSurvival\\n0 = No, 1 = Yes\\npclass\\nTicket class\\n1 = 1st, 2 = 2nd, 3 = 3rd\\nsex\\nSex\\n\\nAge\\nAge in years\\n\\nsibsp\\n# of siblings / spouses aboard the Titanic\\n\\nparch\\n# of parents / children aboard the Titanic\\n\\nticket\\nTicket number\\n\\nfare\\nPassenger fare\\n\\ncabin\\nCabin number\\n\\nembarked\\nPort of Embarkation\\nC = Cherbourg, Q = Queenstown, S = Southampton\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Dictionary\n",
    "Variable\n",
    "\n",
    "survival\n",
    "Survival\n",
    "0 = No, 1 = Yes\n",
    "\n",
    "pclass\n",
    "Ticket class\n",
    "1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "\n",
    "sex\n",
    "Sex\n",
    "\n",
    "Age\n",
    "Age in years\n",
    "\n",
    "sibsp\n",
    "# of siblings / spouses aboard the Titanic\n",
    "\n",
    "parch\n",
    "# of parents / children aboard the Titanic\n",
    "\n",
    "ticket\n",
    "Ticket number\n",
    "\n",
    "fare\n",
    "Passenger fare\n",
    "\n",
    "cabin\n",
    "Cabin number\n",
    "\n",
    "embarked\n",
    "Port of Embarkation\n",
    "C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validationの工夫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
      "       'Cabin', 'Embarked', 'cha', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "Index(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare',\n",
      "       'Cabin', 'Embarked', 'cha', 'C', 'Q', 'S'],\n",
      "      dtype='object')\n",
      "   Pclass                                               Name  Sex   Age  \\\n",
      "0       3                            Braund, Mr. Owen Harris    1  22.0   \n",
      "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0   \n",
      "2       3                             Heikkinen, Miss. Laina    0  26.0   \n",
      "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0   \n",
      "4       3                           Allen, Mr. William Henry    1  35.0   \n",
      "\n",
      "   SibSp  Parch            Ticket     Fare Cabin Embarked  cha  C  Q  S  \n",
      "0      1      0         A/5 21171   7.2500   NaN        S    0  0  0  1  \n",
      "1      1      0          PC 17599  71.2833   C85        C    0  1  0  0  \n",
      "2      0      0  STON/O2. 3101282   7.9250   NaN        S    0  0  0  1  \n",
      "3      1      0            113803  53.1000  C123        S    0  0  0  1  \n",
      "4      0      0            373450   8.0500   NaN        S    0  0  0  1  \n",
      "(1309, 14)\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age          263\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           1\n",
      "Cabin       1014\n",
      "Embarked       0\n",
      "cha            0\n",
      "C              0\n",
      "Q              0\n",
      "S              0\n",
      "dtype: int64\n",
      "          Pclass  Sex       Age  SibSp  Parch        Fare  cha      C      Q  \\\n",
      "Embarked                                                                       \n",
      "C            500  157   6854.42    108    100  16830.7922  102  270.0    0.0   \n",
      "Q            356   63   1431.50     42     14   1526.3085   46    0.0  123.0   \n",
      "S           2148  623  22969.75    503    390  25193.3862  270    0.0    0.0   \n",
      "\n",
      "              S  \n",
      "Embarked         \n",
      "C           0.0  \n",
      "Q           0.0  \n",
      "S         914.0  \n",
      "Pclass    0\n",
      "Sex       0\n",
      "Age       0\n",
      "SibSp     0\n",
      "Parch     0\n",
      "Fare      0\n",
      "S         0\n",
      "Q         0\n",
      "C         0\n",
      "dtype: int64\n",
      "     Pclass  Sex   Age  SibSp  Parch     Fare  S  Q  C\n",
      "370       2    1  21.0      1      0  11.5000  1  0  0\n",
      "271       3    1  25.0      0      0   0.0000  1  0  0\n",
      "798       3    1  30.0      0      0   7.2292  0  0  1\n",
      "807       3    0  18.0      0      0   7.7750  1  0  0\n",
      "371       3    1  18.0      1      0   6.4958  1  0  0\n",
      "(916, 9)\n",
      "(916,)\n",
      "0.907205240175\n",
      "0.595419847328\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "forest = RandomForestClassifier()\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train[\"cha\"] = 0\n",
    "df_test[\"cha\"] = 1\n",
    "df_train[\"Sex\"] = le.fit_transform(df_train[\"Sex\"])\n",
    "df_test[\"Sex\"] = le.fit_transform(df_test[\"Sex\"])\n",
    "s = pd.get_dummies(df_train[\"Embarked\"])\n",
    "df_train = pd.merge(df_train,s,right_index=True,left_index=True)\n",
    "s = pd.get_dummies(df_test[\"Embarked\"])\n",
    "df_test = pd.merge(df_test,s,right_index=True,left_index=True)\n",
    "df_train = df_train.iloc[:,2:]\n",
    "df_test = df_test.iloc[:,1:]\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)\n",
    "print(df_train.head())\n",
    "\n",
    "df_cha = pd.concat([df_train,df_test],axis=0)\n",
    "df_cha[\"Embarked\"].fillna(\"S\",inplace=True)\n",
    "print(df_cha.shape)\n",
    "print(df_cha.isnull().sum())\n",
    "print(df_cha.groupby([\"Embarked\"]).sum())\n",
    "a = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"S\",\"Q\",\"C\"]\n",
    "X_cha = df_cha.ix[:,a]\n",
    "y_cha = df_cha[\"cha\"]\n",
    "X_cha[\"Age\"].fillna(X_cha.Age.mean(),inplace=True)\n",
    "X_cha[\"Fare\"].fillna(X_cha.Fare.mean(),inplace=True)\n",
    "print(X_cha.isnull().sum())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cha, y_cha, test_size = 0.3)\n",
    "forest.fit(X_train, y_train)\n",
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(accuracy_score(y_true=y_train, y_pred=forest.predict(X_train)))\n",
    "print(accuracy_score(y_true=y_test, y_pred=forest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# やりたいこと\n",
    "- PCA、randomforestによる次元削減\n",
    "- テキストデータの変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレーニングデータの量増加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         0       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "    Age Cabin Embarked     Fare Name  Parch  PassengerId  Pclass  SUM Sex  \\\n",
      "0  22.0   NaN        1   7.2500    1    NaN          NaN     3.0  1.0   1   \n",
      "1  38.0   NaN        3  71.2833    4    NaN          NaN     1.0  1.0   0   \n",
      "2  26.0   NaN        1   7.9250    3    NaN          NaN     3.0  0.0   0   \n",
      "3  35.0   NaN        1  53.1000    4    NaN          NaN     1.0  1.0   0   \n",
      "4  35.0   NaN        1   8.0500    1    NaN          NaN     3.0  0.0   1   \n",
      "\n",
      "   SibSp  Survived Ticket  isalone  \n",
      "0    NaN       NaN    NaN      0.0  \n",
      "1    NaN       NaN    NaN      0.0  \n",
      "2    NaN       NaN    NaN      1.0  \n",
      "3    NaN       NaN    NaN      0.0  \n",
      "4    NaN       NaN    NaN      1.0  \n"
     ]
    }
   ],
   "source": [
    "df_result = pd.read_csv(\"predcit_result_data.csv\")\n",
    "df_x_te = pd.read_csv(\"test.csv\")\n",
    "df_result = pd.merge(df_result,df_x_te.iloc[:,1:],right_index=True,left_index=True)\n",
    "df = pd.concat((df,df_result),axis=0,ignore_index=True)\n",
    "print(df_result.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの増加(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  23.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  39.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  27.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  36.0      1   \n",
      "4                           Allen, Mr. William Henry    male  36.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "(2673, 12)\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df_ex1 = df\n",
    "df_ex2 = df\n",
    "df_ex1[\"Age\"] = df_ex1[\"Age\"].apply(lambda x:x+1)\n",
    "df_ex2[\"Age\"] = df_ex2[\"Age\"].apply(lambda x:x-1)\n",
    "print(df_ex.head())\n",
    "df = pd.concat([df,df_ex1,df_ex2],axis=0,ignore_index=True)\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df.ix[:,4]=le.fit_transform(df.ix[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 名前から敬称取り出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def miss_only(text):\n",
    "    text = re.sub(r\".*\\W([a-zA-Z]+?)\\.\\W.*\",r\"\\1\",text)\n",
    "    if text not in [\"Miss\",\"Mr\",\"Master\",\"Mrs\"]:\n",
    "        return \"other\"\n",
    "    else:\n",
    "        return text\n",
    "df[\"Name\"] = df[\"Name\"].map(miss_only)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 子供判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "15           16         1       2   \n",
       "16           17         0       3   \n",
       "17           18         1       2   \n",
       "18           19         0       3   \n",
       "19           20         1       3   \n",
       "\n",
       "                                                 Name  Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    1  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina    0  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1   \n",
       "4                            Allen, Mr. William Henry    1  35.0      0   \n",
       "5                                    Moran, Mr. James    1   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    1  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    1   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)    0  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)    0  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut    0   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth    0  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    1  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    1  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina    0  14.0      0   \n",
       "15                   Hewlett, Mrs. (Mary D Kingcome)     0  55.0      0   \n",
       "16                               Rice, Master. Eugene    1   2.0      4   \n",
       "17                       Williams, Mr. Charles Eugene    1   NaN      0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...    0  31.0      1   \n",
       "19                            Masselmani, Mrs. Fatima    0   NaN      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  child  \n",
       "0       0         A/5 21171   7.2500   NaN        S      0  \n",
       "1       0          PC 17599  71.2833   C85        C      0  \n",
       "2       0  STON/O2. 3101282   7.9250   NaN        S      0  \n",
       "3       0            113803  53.1000  C123        S      0  \n",
       "4       0            373450   8.0500   NaN        S      0  \n",
       "5       0            330877   8.4583   NaN        Q      0  \n",
       "6       0             17463  51.8625   E46        S      0  \n",
       "7       1            349909  21.0750   NaN        S      1  \n",
       "8       2            347742  11.1333   NaN        S      0  \n",
       "9       0            237736  30.0708   NaN        C      1  \n",
       "10      1           PP 9549  16.7000    G6        S      1  \n",
       "11      0            113783  26.5500  C103        S      0  \n",
       "12      0         A/5. 2151   8.0500   NaN        S      0  \n",
       "13      5            347082  31.2750   NaN        S      0  \n",
       "14      0            350406   7.8542   NaN        S      1  \n",
       "15      0            248706  16.0000   NaN        S      0  \n",
       "16      1            382652  29.1250   NaN        Q      1  \n",
       "17      0            244373  13.0000   NaN        S      0  \n",
       "18      0            345763  18.0000   NaN        S      0  \n",
       "19      0              2649   7.2250   NaN        C      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"child\"]=df[\"Age\"].apply(lambda x:1 if x < 15 else 0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embarkedの違う変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  \n",
       "0         A/5 21171   7.2500   NaN       1.0  \n",
       "1          PC 17599  71.2833   C85       3.0  \n",
       "2  STON/O2. 3101282   7.9250   NaN       1.0  \n",
       "3            113803  53.1000  C123       1.0  \n",
       "4            373450   8.0500   NaN       1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Embarked\"]=df[\"Embarked\"].map({\"S\":1,\"Q\":2,\"C\":3})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cabin情報の活用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  \n",
       "0         A/5 21171   7.2500   NaN       1.0  \n",
       "1          PC 17599  71.2833     C       3.0  \n",
       "2  STON/O2. 3101282   7.9250   NaN       1.0  \n",
       "3            113803  53.1000     C       1.0  \n",
       "4            373450   8.0500   NaN       1.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cabin_cha(text):\n",
    "    if type(text) is str:\n",
    "        return text[0]\n",
    "    else:\n",
    "        return \"NaN\"\n",
    "df[\"Cabin\"] = df[\"Cabin\"].apply(cabin_cha)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 年齢の詳細な補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef name_classifier(name_df):    \\n    name_class_df = pd.DataFrame(columns=['miss','mrs','master','mr'])\\n    \\n    for name in name_df:        \\n        if 'Miss.' in name:\\n            df = pd.DataFrame([[1,0,0,0]],columns=['miss','mrs','master','mr'])\\n        elif 'Mrs.' in name:\\n            df = pd.DataFrame([[0,1,0,0]],columns=['miss','mrs','master','mr'])\\n        elif 'Master.' in name:\\n            df = pd.DataFrame([[0,0,1,0]],columns=['miss','mrs','master','mr'])\\n        elif 'Mr.' in name:\\n            df = pd.DataFrame([[0,0,0,1]],columns=['miss','mrs','master','mr'])\\n        else :\\n            df = pd.DataFrame([[0,0,0,0]],columns=['miss','mrs','master','mr'])\\n        name_class_df = name_class_df.append(df,ignore_index=True)        \\n    return name_class_df\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def name_classifier(name_df):    \n",
    "    name_class_df = pd.DataFrame(columns=['miss','mrs','master','mr'])\n",
    "    \n",
    "    for name in name_df:        \n",
    "        if 'Miss.' in name:\n",
    "            df = pd.DataFrame([[1,0,0,0]],columns=['miss','mrs','master','mr'])\n",
    "        elif 'Mrs.' in name:\n",
    "            df = pd.DataFrame([[0,1,0,0]],columns=['miss','mrs','master','mr'])\n",
    "        elif 'Master.' in name:\n",
    "            df = pd.DataFrame([[0,0,1,0]],columns=['miss','mrs','master','mr'])\n",
    "        elif 'Mr.' in name:\n",
    "            df = pd.DataFrame([[0,0,0,1]],columns=['miss','mrs','master','mr'])\n",
    "        else :\n",
    "            df = pd.DataFrame([[0,0,0,0]],columns=['miss','mrs','master','mr'])\n",
    "        name_class_df = name_class_df.append(df,ignore_index=True)        \n",
    "    return name_class_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ss=name_classifier(df[\"Name\"])\n",
    "#ss=pd.DataFrame(ss.values,index=range(1,892),columns=[\"miss\",\"mrs\",\"master\",\"mr\"])\n",
    "#df=pd.merge(df,ss,right_index=True,left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 家族の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_maker(x,y):\n",
    "    sums=pd.DataFrame(columns=[\"SUM\"])\n",
    "    for i in range(len(x)):\n",
    "        s=pd.DataFrame([int(x[i])+int(y[i])],columns=[\"SUM\"])\n",
    "        sums=sums.append(s,ignore_index=True)\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked SUM  \n",
       "0         A/5 21171   7.2500   NaN       1.0   1  \n",
       "1          PC 17599  71.2833   C85       3.0   1  \n",
       "2  STON/O2. 3101282   7.9250   NaN       1.0   0  \n",
       "3            113803  53.1000  C123       1.0   1  \n",
       "4            373450   8.0500   NaN       1.0   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums=sum_maker(df[\"SibSp\"].values,df[\"Parch\"].values)\n",
    "sums=pd.DataFrame(sums.values,index=range(df.shape[0]),columns=[\"SUM\"])\n",
    "df=pd.merge(df,sums,right_index=True,left_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isaloneの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>SUM</th>\n",
       "      <th>isalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    Mr    1  22.0      1      0   \n",
       "1            2         1       1   Mrs    0  38.0      1      0   \n",
       "2            3         1       3  Miss    0  26.0      0      0   \n",
       "3            4         1       1   Mrs    0  35.0      1      0   \n",
       "4            5         0       3    Mr    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked SUM  isalone  \n",
       "0         A/5 21171   7.2500   NaN       1.0   1        0  \n",
       "1          PC 17599  71.2833   C85       3.0   1        0  \n",
       "2  STON/O2. 3101282   7.9250   NaN       1.0   0        1  \n",
       "3            113803  53.1000  C123       1.0   1        0  \n",
       "4            373450   8.0500   NaN       1.0   0        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"isalone\"] = df[\"SUM\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名前の処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name(x):\n",
    "    namesum1=[]\n",
    "    namesum={}\n",
    "    namesum2=[]\n",
    "    for i in range(len(x)):\n",
    "        name=x[i].split(\",\")\n",
    "        if name[0] in namesum1:\n",
    "            namesum1.append(name[0])\n",
    "            namesum[name[0]]+=1\n",
    "        else:\n",
    "            namesum[name[0]]=1\n",
    "            namesum1.append(name[0])\n",
    "    for p in range(len(namesum1)):\n",
    "        namesum2.append([namesum1[p],namesum[namesum1[p]]])\n",
    "    namesum3=pd.DataFrame(namesum2,index=range(len(namesum1)),columns=[\"myoji\",\"namesum\"])\n",
    "    return namesum3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "namesum=name(df[\"Name\"])\n",
    "df=pd.merge(df,namesum,right_index=True,left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embarked のdummy化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=pd.get_dummies(df[\"Embarked\"])\n",
    "df=pd.merge(df,s,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId',    'Survived',      'Pclass',        'Name',\n",
      "               'Sex',         'Age',       'SibSp',       'Parch',\n",
      "            'Ticket',        'Fare',       'Cabin',    'Embarked',\n",
      "              'miss',         'mrs',      'master',          'mr',\n",
      "               'SUM',     'isalone',       'myoji',     'namesum',\n",
      "                 1.0,           2.0,           3.0],\n",
      "      dtype='object')\n",
      "23\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare ...   mrs  master   mr  SUM  isalone      myoji  \\\n",
      "0         A/5 21171   7.2500 ...   0.0     0.0  1.0  1.0        0     Braund   \n",
      "1          PC 17599  71.2833 ...   1.0     0.0  0.0  1.0        0    Cumings   \n",
      "2  STON/O2. 3101282   7.9250 ...   0.0     0.0  0.0  0.0        1  Heikkinen   \n",
      "3            113803  53.1000 ...   1.0     0.0  0.0  1.0        0   Futrelle   \n",
      "4            373450   8.0500 ...   0.0     0.0  1.0  0.0        1      Allen   \n",
      "\n",
      "   namesum  1.0 2.0  3.0  \n",
      "0        2    1   0    0  \n",
      "1        1    0   0    1  \n",
      "2        1    1   0    0  \n",
      "3        2    1   0    0  \n",
      "4        2    1   0    0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(len(df.columns))\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = ['Pclass', 'Sex', 'Age', 'Fare', 'SUM',\"Name\",\n",
    "       \"Embarked\",\"isalone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df2 = df\n",
    "df = df2.ix[:,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SUM</th>\n",
       "      <th>Name</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>isalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>Miss</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>4</td>\n",
       "      <td>Master</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age     Fare SUM    Name  Embarked  isalone\n",
       "0       3    1  22.0   7.2500   1      Mr       1.0        0\n",
       "1       1    0  38.0  71.2833   1     Mrs       3.0        0\n",
       "2       3    0  26.0   7.9250   0    Miss       1.0        1\n",
       "3       1    0  35.0  53.1000   1     Mrs       1.0        0\n",
       "4       3    1  35.0   8.0500   0      Mr       1.0        1\n",
       "5       3    1   NaN   8.4583   0      Mr       2.0        1\n",
       "6       1    1  54.0  51.8625   0      Mr       1.0        1\n",
       "7       3    1   2.0  21.0750   4  Master       1.0        0\n",
       "8       3    0  27.0  11.1333   2     Mrs       1.0        0\n",
       "9       2    0  14.0  30.0708   1     Mrs       3.0        0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SUM</th>\n",
       "      <th>Name</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>isalone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age     Fare SUM  Name  Embarked  isalone\n",
       "0       3    1  22.0   7.2500   1     1       1.0        0\n",
       "1       1    0  38.0  71.2833   1     4       3.0        0\n",
       "2       3    0  26.0   7.9250   0     3       1.0        1\n",
       "3       1    0  35.0  53.1000   1     4       1.0        0\n",
       "4       3    1  35.0   8.0500   0     1       1.0        1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_to_num = {\"Mr\":1,\"Master\":2,\"Miss\":3,\"Mrs\":4,\"other\":5}\n",
    "df[\"Name\"] = df[\"Name\"].map(mr_to_num)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "df[\"Embarked\"].fillna(1)\n",
    "\n",
    "imr1=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imr2=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imr3=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imr4=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "\n",
    "df[df[\"Name\"]==1]=imr1.fit_transform(df[df[\"Name\"]==1])\n",
    "df[df[\"Name\"]==2]=imr2.fit_transform(df[df[\"Name\"]==2])\n",
    "df[df[\"Name\"]==3]=imr3.fit_transform(df[df[\"Name\"]==3])\n",
    "df[df[\"Name\"]==4]=imr4.fit_transform(df[df[\"Name\"]==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex        Age     Fare  SUM  Name  Embarked  isalone\n",
      "0      3.0  1.0  22.000000   7.2500  1.0   1.0       1.0      0.0\n",
      "1      1.0  0.0  38.000000  71.2833  1.0   4.0       3.0      0.0\n",
      "2      3.0  0.0  26.000000   7.9250  0.0   3.0       1.0      1.0\n",
      "3      1.0  0.0  35.000000  53.1000  1.0   4.0       1.0      0.0\n",
      "4      3.0  1.0  35.000000   8.0500  0.0   1.0       1.0      1.0\n",
      "5      3.0  1.0  32.368090   8.4583  0.0   1.0       2.0      1.0\n",
      "6      1.0  1.0  54.000000  51.8625  0.0   1.0       1.0      1.0\n",
      "7      3.0  1.0   2.000000  21.0750  4.0   2.0       1.0      0.0\n",
      "8      3.0  0.0  27.000000  11.1333  2.0   4.0       1.0      0.0\n",
      "9      2.0  0.0  14.000000  30.0708  1.0   4.0       3.0      0.0\n",
      "10     3.0  0.0   4.000000  16.7000  2.0   3.0       1.0      0.0\n",
      "11     1.0  0.0  58.000000  26.5500  0.0   3.0       1.0      1.0\n",
      "12     3.0  1.0  20.000000   8.0500  0.0   1.0       1.0      1.0\n",
      "13     3.0  1.0  39.000000  31.2750  6.0   1.0       1.0      0.0\n",
      "14     3.0  0.0  14.000000   7.8542  0.0   3.0       1.0      1.0\n",
      "15     2.0  0.0  55.000000  16.0000  0.0   4.0       1.0      1.0\n",
      "16     3.0  1.0   2.000000  29.1250  5.0   2.0       2.0      0.0\n",
      "17     2.0  1.0  32.368090  13.0000  0.0   1.0       1.0      1.0\n",
      "18     3.0  0.0  31.000000  18.0000  1.0   4.0       1.0      0.0\n",
      "19     3.0  0.0  35.728972   7.2250  0.0   4.0       3.0      1.0\n"
     ]
    }
   ],
   "source": [
    "imr=Imputer(missing_values=\"NaN\",strategy=\"mean\",axis=0)\n",
    "imr.fit(df)\n",
    "df=pd.DataFrame(imr.transform(df),columns=a)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical_ageの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex       Age     Fare  SUM  Name  Embarked  isalone\n",
      "0     3.0  1.0  22.00000   7.2500  1.0   1.0       1.0      0.0\n",
      "1     1.0  0.0  38.00000  71.2833  1.0   4.0       3.0      0.0\n",
      "2     3.0  0.0  26.00000   7.9250  0.0   3.0       1.0      1.0\n",
      "3     1.0  0.0  35.00000  53.1000  1.0   4.0       1.0      0.0\n",
      "4     3.0  1.0  35.00000   8.0500  0.0   1.0       1.0      1.0\n",
      "5     3.0  1.0  32.36809   8.4583  0.0   1.0       2.0      1.0\n",
      "6     1.0  1.0  54.00000  51.8625  0.0   1.0       1.0      1.0\n",
      "7     3.0  1.0   2.00000  21.0750  4.0   2.0       1.0      0.0\n",
      "8     3.0  0.0  27.00000  11.1333  2.0   4.0       1.0      0.0\n",
      "9     2.0  0.0  14.00000  30.0708  1.0   4.0       3.0      0.0\n",
      "0     (16.336, 32.252]\n",
      "1     (32.252, 48.168]\n",
      "2     (16.336, 32.252]\n",
      "3     (32.252, 48.168]\n",
      "4     (32.252, 48.168]\n",
      "5     (32.252, 48.168]\n",
      "6     (48.168, 64.084]\n",
      "7       (0.34, 16.336]\n",
      "8     (16.336, 32.252]\n",
      "9       (0.34, 16.336]\n",
      "10      (0.34, 16.336]\n",
      "11    (48.168, 64.084]\n",
      "12    (16.336, 32.252]\n",
      "13    (32.252, 48.168]\n",
      "14      (0.34, 16.336]\n",
      "15    (48.168, 64.084]\n",
      "16      (0.34, 16.336]\n",
      "17    (32.252, 48.168]\n",
      "18    (16.336, 32.252]\n",
      "19    (32.252, 48.168]\n",
      "20    (32.252, 48.168]\n",
      "21    (32.252, 48.168]\n",
      "22      (0.34, 16.336]\n",
      "23    (16.336, 32.252]\n",
      "24      (0.34, 16.336]\n",
      "25    (32.252, 48.168]\n",
      "26    (32.252, 48.168]\n",
      "27    (16.336, 32.252]\n",
      "28    (16.336, 32.252]\n",
      "29    (32.252, 48.168]\n",
      "Name: Categorical_Age, dtype: category\n",
      "Categories (5, interval[float64]): [(0.34, 16.336] < (16.336, 32.252] < (32.252, 48.168] < (48.168, 64.084] < (64.084, 80.0]]\n"
     ]
    }
   ],
   "source": [
    "#df2 = df\n",
    "print(df.head(10))\n",
    "df[\"Categorical_Age\"]=pd.cut(df[\"Age\"],5)\n",
    "print(df[\"Categorical_Age\"].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex  Age     Fare  SUM  Name  Embarked  isalone   Categorical_Age\n",
      "0     3.0  1.0  1.0   7.2500  1.0   1.0       1.0      0.0  (16.336, 32.252]\n",
      "1     1.0  0.0  2.0  71.2833  1.0   4.0       3.0      0.0  (32.252, 48.168]\n",
      "2     3.0  0.0  1.0   7.9250  0.0   3.0       1.0      1.0  (16.336, 32.252]\n",
      "3     1.0  0.0  2.0  53.1000  1.0   4.0       1.0      0.0  (32.252, 48.168]\n",
      "4     3.0  1.0  2.0   8.0500  0.0   1.0       1.0      1.0  (32.252, 48.168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.ix[df[\"Age\"] < 16.336,\"Age\"] = 0\n",
    "df.ix[(df[\"Age\"] < 32.252) & (df[\"Age\"] >= 16.336),\"Age\"] = 1\n",
    "df.ix[(df[\"Age\"] < 48.168) & (df[\"Age\"] >= 32.252),\"Age\"] = 2\n",
    "df.ix[(df[\"Age\"] < 64.084) & (df[\"Age\"] >= 48.168),\"Age\"] = 3\n",
    "df.ix[df[\"Age\"] >= 64.084,\"Age\"] = 4\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical fareの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Pclass  Sex  Age     Fare  SUM  Name  Embarked  isalone   Categorical_Age  \\\n",
      "0      3.0  1.0  1.0   7.2500  1.0   1.0       1.0      0.0  (16.336, 32.252]   \n",
      "1      1.0  0.0  2.0  71.2833  1.0   4.0       3.0      0.0  (32.252, 48.168]   \n",
      "2      3.0  0.0  1.0   7.9250  0.0   3.0       1.0      1.0  (16.336, 32.252]   \n",
      "3      1.0  0.0  2.0  53.1000  1.0   4.0       1.0      0.0  (32.252, 48.168]   \n",
      "4      3.0  1.0  2.0   8.0500  0.0   1.0       1.0      1.0  (32.252, 48.168]   \n",
      "5      3.0  1.0  2.0   8.4583  0.0   1.0       2.0      1.0  (32.252, 48.168]   \n",
      "6      1.0  1.0  3.0  51.8625  0.0   1.0       1.0      1.0  (48.168, 64.084]   \n",
      "7      3.0  1.0  0.0  21.0750  4.0   2.0       1.0      0.0    (0.34, 16.336]   \n",
      "8      3.0  0.0  1.0  11.1333  2.0   4.0       1.0      0.0  (16.336, 32.252]   \n",
      "9      2.0  0.0  0.0  30.0708  1.0   4.0       3.0      0.0    (0.34, 16.336]   \n",
      "10     3.0  0.0  0.0  16.7000  2.0   3.0       1.0      0.0    (0.34, 16.336]   \n",
      "11     1.0  0.0  3.0  26.5500  0.0   3.0       1.0      1.0  (48.168, 64.084]   \n",
      "12     3.0  1.0  1.0   8.0500  0.0   1.0       1.0      1.0  (16.336, 32.252]   \n",
      "13     3.0  1.0  2.0  31.2750  6.0   1.0       1.0      0.0  (32.252, 48.168]   \n",
      "14     3.0  0.0  0.0   7.8542  0.0   3.0       1.0      1.0    (0.34, 16.336]   \n",
      "15     2.0  0.0  3.0  16.0000  0.0   4.0       1.0      1.0  (48.168, 64.084]   \n",
      "16     3.0  1.0  0.0  29.1250  5.0   2.0       2.0      0.0    (0.34, 16.336]   \n",
      "17     2.0  1.0  2.0  13.0000  0.0   1.0       1.0      1.0  (32.252, 48.168]   \n",
      "18     3.0  0.0  1.0  18.0000  1.0   4.0       1.0      0.0  (16.336, 32.252]   \n",
      "19     3.0  0.0  2.0   7.2250  0.0   4.0       3.0      1.0  (32.252, 48.168]   \n",
      "\n",
      "   Categorical_Fare  \n",
      "0    (-0.001, 7.91]  \n",
      "1   (31.0, 512.329]  \n",
      "2    (7.91, 14.454]  \n",
      "3   (31.0, 512.329]  \n",
      "4    (7.91, 14.454]  \n",
      "5    (7.91, 14.454]  \n",
      "6   (31.0, 512.329]  \n",
      "7    (14.454, 31.0]  \n",
      "8    (7.91, 14.454]  \n",
      "9    (14.454, 31.0]  \n",
      "10   (14.454, 31.0]  \n",
      "11   (14.454, 31.0]  \n",
      "12   (7.91, 14.454]  \n",
      "13  (31.0, 512.329]  \n",
      "14   (-0.001, 7.91]  \n",
      "15   (14.454, 31.0]  \n",
      "16   (14.454, 31.0]  \n",
      "17   (7.91, 14.454]  \n",
      "18   (14.454, 31.0]  \n",
      "19   (-0.001, 7.91]  \n"
     ]
    }
   ],
   "source": [
    "#df2 = df\n",
    "#df = df2\n",
    "df[\"Categorical_Fare\"]=pd.qcut(df[\"Fare\"],4)\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex  Age  Fare  SUM  Name  Embarked  isalone   Categorical_Age  \\\n",
      "0     3.0  1.0  1.0   0.0  1.0   1.0       1.0      0.0  (16.336, 32.252]   \n",
      "1     1.0  0.0  2.0   3.0  1.0   4.0       3.0      0.0  (32.252, 48.168]   \n",
      "2     3.0  0.0  1.0   1.0  0.0   3.0       1.0      1.0  (16.336, 32.252]   \n",
      "3     1.0  0.0  2.0   3.0  1.0   4.0       1.0      0.0  (32.252, 48.168]   \n",
      "4     3.0  1.0  2.0   1.0  0.0   1.0       1.0      1.0  (32.252, 48.168]   \n",
      "\n",
      "  Categorical_Fare  \n",
      "0   (-0.001, 7.91]  \n",
      "1  (31.0, 512.329]  \n",
      "2   (7.91, 14.454]  \n",
      "3  (31.0, 512.329]  \n",
      "4   (7.91, 14.454]  \n"
     ]
    }
   ],
   "source": [
    "df.ix[df[\"Fare\"] < 7.91,\"Fare\"] = 0\n",
    "df.ix[(df[\"Fare\"] < 14.454) & (df[\"Fare\"] >= 7.91),\"Fare\"] = 1\n",
    "df.ix[(df[\"Fare\"] < 31) & (df[\"Fare\"] >= 14.454),\"Fare\"] = 2\n",
    "df.ix[df[\"Fare\"] >= 31,\"Fare\"] = 3\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     1\n",
       "16     0\n",
       "17     1\n",
       "18     0\n",
       "19     1\n",
       "20     0\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     0\n",
       "25     1\n",
       "26     0\n",
       "27     0\n",
       "28     1\n",
       "29     0\n",
       "      ..\n",
       "861    0\n",
       "862    1\n",
       "863    0\n",
       "864    0\n",
       "865    1\n",
       "866    1\n",
       "867    0\n",
       "868    0\n",
       "869    1\n",
       "870    0\n",
       "871    1\n",
       "872    0\n",
       "873    0\n",
       "874    1\n",
       "875    1\n",
       "876    0\n",
       "877    0\n",
       "878    0\n",
       "879    1\n",
       "880    1\n",
       "881    0\n",
       "882    0\n",
       "883    0\n",
       "884    0\n",
       "885    0\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df2.iloc[:,1]\n",
    "x=df\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1=StandardScaler()\n",
    "sc2=StandardScaler()\n",
    "sc3=StandardScaler()\n",
    "sc4=StandardScaler()\n",
    "x[\"Fare\"]= sc1.fit_transform(x[\"Fare\"].reshape(len(x[\"Fare\"].values),1))\n",
    "#x[\"SibSp\"]=sc2.fit_transform(x[\"SibSp\"])\n",
    "#x[\"Parch\"]=sc3.fit_transform(x[\"Parch\"])\n",
    "x[\"Age\"]=sc4.fit_transform(x[\"Age\"].reshape(len(x[\"Fare\"].values),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SUM</th>\n",
       "      <th>Name</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>isalone</th>\n",
       "      <th>Categorical_Age</th>\n",
       "      <th>Categorical_Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(16.336, 32.252]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(32.252, 48.168]</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Fare  SUM  Name  Embarked  isalone   Categorical_Age  \\\n",
       "0     3.0  1.0  1.0   0.0  1.0   1.0       1.0      0.0  (16.336, 32.252]   \n",
       "1     1.0  0.0  2.0   3.0  1.0   4.0       3.0      0.0  (32.252, 48.168]   \n",
       "2     3.0  0.0  1.0   1.0  0.0   3.0       1.0      1.0  (16.336, 32.252]   \n",
       "3     1.0  0.0  2.0   3.0  1.0   4.0       1.0      0.0  (32.252, 48.168]   \n",
       "4     3.0  1.0  2.0   1.0  0.0   1.0       1.0      1.0  (32.252, 48.168]   \n",
       "\n",
       "  Categorical_Fare  \n",
       "0   (-0.001, 7.91]  \n",
       "1  (31.0, 512.329]  \n",
       "2   (7.91, 14.454]  \n",
       "3  (31.0, 512.329]  \n",
       "4   (7.91, 14.454]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = [\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"isalone\",\"Embarked\",\"SUM\"]\n",
    "x = x.ix[:,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomforestによる重要度検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  6, 10], dtype=int32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_ind = [4,3,2,1,2.5]\n",
    "a = np.arange(5)\n",
    "print(a)\n",
    "\n",
    "a[np.argsort(new_ind)]\n",
    "np.cumsum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "def forest_decomposition(x_train,x_test,y_train,n_components=5):\n",
    "    forest.fit(x_train,y_train)\n",
    "    print([[name, ratio] for name,ratio in zip(x_train.columns, forest.feature_importances_)])\n",
    "    print(forest.feature_importances_)\n",
    "    new_ind = forest.feature_importances_\n",
    "    print(x_train.columns[np.argsort(new_ind)[::-1]])\n",
    "    x_train = x_train[x_train.columns[np.argsort(new_ind)[::-1]]]\n",
    "    x_test=x_test[x_test.columns[np.argsort(new_ind)]]\n",
    "    plt.plot(range(x_train.shape[1]),np.sort(new_ind)[::-1])\n",
    "    plt.plot(range(x_train.shape[1]),np.cumsum(np.sort(new_ind)[::-1]))\n",
    "    x_train = x_train.ix[:,:n_components]\n",
    "    x_test = x_test.ix[:,:n_components]\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Pclass', 0.10201670674267897], ['Sex', 0.078310769385890627], ['Age', 0.19743562856814414], ['SibSp', 0.026783098192448358], ['Parch', 0.022728264779532017], ['Fare', 0.18626190859481986], ['miss', 0.034907203060795915], ['mrs', 0.038147544933833724], ['master', 0.0085088673135530063], ['mr', 0.16275808587933105], ['SUM', 0.047202912226067317], ['namesum', 0.048064433162418277], ['C', 0.013393474665950205], ['Q', 0.011163136866007853], ['S', 0.022317965628528648]]\n",
      "[ 0.10201671  0.07831077  0.19743563  0.0267831   0.02272826  0.18626191\n",
      "  0.0349072   0.03814754  0.00850887  0.16275809  0.04720291  0.04806443\n",
      "  0.01339347  0.01116314  0.02231797]\n",
      "Index(['Age', 'Fare', 'mr', 'Pclass', 'Sex', 'namesum', 'SUM', 'mrs', 'miss',\n",
      "       'SibSp', 'Parch', 'S', 'C', 'Q', 'master'],\n",
      "      dtype='object')\n",
      "(623, 3)\n",
      "      Age      Fare   mr\n",
      "857  51.0   26.5500  1.0\n",
      "52   49.0   76.7292  0.0\n",
      "386   1.0   46.9000  0.0\n",
      "124  54.0   77.2875  1.0\n",
      "578  35.0   14.4583  0.0\n",
      "549   8.0   36.7500  0.0\n",
      "118  24.0  247.5208  1.0\n",
      "12   20.0    8.0500  1.0\n",
      "157  30.0    8.0500  1.0\n",
      "127  24.0    7.1417  1.0\n",
      "653  21.0    7.8292  0.0\n",
      "235  21.0    7.5500  0.0\n",
      "785  25.0    7.2500  1.0\n",
      "241  21.0   15.5000  0.0\n",
      "351  30.0   35.0000  1.0\n",
      "862  48.0   25.9292  0.0\n",
      "851  74.0    7.7750  1.0\n",
      "753  23.0    7.8958  1.0\n",
      "532  17.0    7.2292  1.0\n",
      "485  21.0   25.4667  0.0\n",
      "695  52.0   13.5000  1.0\n",
      "475  30.0   52.0000  1.0\n",
      "17   30.0   13.0000  1.0\n",
      "476  34.0   21.0000  1.0\n",
      "533  35.0   22.3583  0.0\n",
      "416  34.0   32.5000  0.0\n",
      "345  24.0   13.0000  0.0\n",
      "242  29.0   10.5000  1.0\n",
      "344  36.0   13.0000  1.0\n",
      "170  61.0   33.5000  1.0\n",
      "..    ...       ...  ...\n",
      "72   21.0   73.5000  1.0\n",
      "845  42.0    7.5500  1.0\n",
      "537  30.0  106.4250  0.0\n",
      "677  18.0    9.8417  0.0\n",
      "849  35.0   89.1042  0.0\n",
      "874  28.0   24.0000  0.0\n",
      "174  56.0   30.6958  1.0\n",
      "87   30.0    8.0500  1.0\n",
      "551  27.0   26.0000  1.0\n",
      "486  35.0   90.0000  0.0\n",
      "705  39.0   26.0000  1.0\n",
      "314  43.0   26.2500  1.0\n",
      "396  31.0    7.8542  0.0\n",
      "600  24.0   27.0000  0.0\n",
      "472  33.0   27.7500  0.0\n",
      "70   32.0   10.5000  1.0\n",
      "599  49.0   56.9292  0.0\n",
      "804  27.0    6.9750  1.0\n",
      "754  48.0   65.0000  0.0\n",
      "277  30.0    0.0000  1.0\n",
      "723  50.0   13.0000  1.0\n",
      "9    14.0   30.0708  0.0\n",
      "359  21.0    7.8792  0.0\n",
      "707  42.0   26.2875  1.0\n",
      "763  36.0  120.0000  0.0\n",
      "835  39.0   83.1583  0.0\n",
      "192  19.0    7.8542  0.0\n",
      "629  30.0    7.7333  1.0\n",
      "559  36.0   17.4000  0.0\n",
      "684  60.0   39.0000  1.0\n",
      "\n",
      "[623 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d07a51e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, x_test = forest_decomposition(x_train,x_test,y_train,n_components=3)\n",
    "print(x_train.shape)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCAによる次元圧縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93015764  0.06984236]\n",
      "(623, 2)\n",
      "[[ -5.21992052  21.67574017]\n",
      " [ 44.89083361  17.97444368]\n",
      " [ 13.59941096 -29.43064452]\n",
      " ..., \n",
      " [-24.71740219   1.30580807]\n",
      " [-14.85062661   6.91835302]\n",
      " [  7.52996583  30.07488324]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(x_train,y_train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDAによる次元圧縮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0102694  -0.01653719]]\n",
      "(623, 1)\n",
      "[[ -7.84254708e-01]\n",
      " [  3.11666476e-01]\n",
      " [  1.19211434e+00]\n",
      " [  1.66544903e-01]\n",
      " [ -5.37539175e-01]\n",
      " [  7.54507309e-01]\n",
      " [  4.58369878e+00]\n",
      " [ -2.09980199e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -3.51736135e-01]\n",
      " [ -2.44459262e-01]\n",
      " [ -2.50249752e-01]\n",
      " [ -3.80292157e-01]\n",
      " [ -8.38852445e-02]\n",
      " [  3.45562797e-02]\n",
      " [ -7.05266287e-01]\n",
      " [ -1.87671072e+00]\n",
      " [ -3.05480922e-01]\n",
      " [ -1.28477172e-01]\n",
      " [  1.28733102e-01]\n",
      " [ -1.08247269e+00]\n",
      " [  3.83450353e-01]\n",
      " [ -4.13678803e-01]\n",
      " [ -3.72349972e-01]\n",
      " [ -3.72944844e-01]\n",
      " [ -1.35099456e-01]\n",
      " [ -2.28235986e-01]\n",
      " [ -4.37094759e-01]\n",
      " [ -6.01237587e-01]\n",
      " [ -9.50367659e-01]\n",
      " [ -6.00544840e-01]\n",
      " [ -5.39680221e-01]\n",
      " [  2.29272968e-01]\n",
      " [ -2.32892346e-01]\n",
      " [ -2.70053636e-01]\n",
      " [  8.14831785e-01]\n",
      " [  5.51197068e-02]\n",
      " [ -2.46084698e-01]\n",
      " [ -8.27265104e-01]\n",
      " [  7.18452628e-01]\n",
      " [ -1.08267638e+00]\n",
      " [ -3.97816970e-01]\n",
      " [ -5.39680221e-01]\n",
      " [ -3.48780543e-01]\n",
      " [ -1.81040618e-01]\n",
      " [ -5.34185572e-01]\n",
      " [ -2.90521507e-01]\n",
      " [ -2.98145347e-01]\n",
      " [  1.72509618e-02]\n",
      " [ -4.57229732e-01]\n",
      " [  1.58752762e+00]\n",
      " [ -5.51111107e-01]\n",
      " [ -5.34547854e-01]\n",
      " [  9.46024984e-02]\n",
      " [  1.73888258e+00]\n",
      " [ -3.54519640e-01]\n",
      " [  8.14741853e-02]\n",
      " [ -3.60701881e-01]\n",
      " [ -1.48938096e-01]\n",
      " [ -7.84519670e-01]\n",
      " [  2.87460200e-01]\n",
      " [ -1.70237983e-01]\n",
      " [ -4.05502738e-01]\n",
      " [ -4.64351961e-01]\n",
      " [  3.90786426e-01]\n",
      " [ -1.29307931e-01]\n",
      " [ -6.66647936e-01]\n",
      " [ -7.50463812e-01]\n",
      " [ -2.88404589e-01]\n",
      " [ -1.21611850e+00]\n",
      " [ -6.01436117e-02]\n",
      " [ -1.05742318e+00]\n",
      " [ -5.20931701e-01]\n",
      " [ -6.56189081e-02]\n",
      " [ -2.45975874e-01]\n",
      " [ -3.23891876e-01]\n",
      " [  5.01506703e-01]\n",
      " [  5.63360987e-01]\n",
      " [ -4.36739366e-01]\n",
      " [ -3.69718825e-02]\n",
      " [ -2.46402756e-01]\n",
      " [ -4.16850195e-01]\n",
      " [  1.60810109e+00]\n",
      " [ -6.67558178e-01]\n",
      " [ -6.92183622e-01]\n",
      " [ -1.17027632e+00]\n",
      " [ -3.03596502e-01]\n",
      " [ -6.13267750e-01]\n",
      " [  9.25221834e-01]\n",
      " [ -4.58603616e-01]\n",
      " [ -5.39680221e-01]\n",
      " [ -1.02170577e-01]\n",
      " [  1.28733102e-01]\n",
      " [  1.90877485e+00]\n",
      " [  6.80211355e-01]\n",
      " [  2.33057134e-01]\n",
      " [ -1.53295988e-01]\n",
      " [  1.23593308e+00]\n",
      " [ -3.04110925e-01]\n",
      " [ -8.68654674e-02]\n",
      " [ -3.97987313e-01]\n",
      " [  4.85448536e-01]\n",
      " [ -1.53639826e-01]\n",
      " [  6.06938860e-01]\n",
      " [ -1.12410763e+00]\n",
      " [  7.38155023e-01]\n",
      " [  1.28733102e-01]\n",
      " [ -3.58059972e-01]\n",
      " [ -1.14172181e-01]\n",
      " [ -1.80221587e-01]\n",
      " [  4.33614564e-01]\n",
      " [ -7.28531370e-01]\n",
      " [ -1.51104045e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -9.21912840e-02]\n",
      " [ -3.39601976e-01]\n",
      " [ -2.45889677e-01]\n",
      " [ -4.86988344e-01]\n",
      " [ -5.34634051e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -5.56825292e-02]\n",
      " [  5.92617740e-01]\n",
      " [ -5.38357650e-01]\n",
      " [  8.21271259e-01]\n",
      " [ -4.20063080e-01]\n",
      " [ -4.90579901e-01]\n",
      " [ -5.20867102e-01]\n",
      " [ -6.92880889e-01]\n",
      " [  3.97121988e-01]\n",
      " [ -2.24731332e-01]\n",
      " [ -4.77767463e-01]\n",
      " [ -8.14219940e-02]\n",
      " [ -3.03500710e-01]\n",
      " [  8.53284747e-01]\n",
      " [  3.42403992e-01]\n",
      " [ -5.42430938e-01]\n",
      " [ -3.94652296e-01]\n",
      " [  3.11217954e-01]\n",
      " [ -4.48699158e-02]\n",
      " [ -9.06092152e-01]\n",
      " [  7.46729023e-01]\n",
      " [ -2.43324279e-01]\n",
      " [ -4.16565490e-01]\n",
      " [ -4.59374336e-01]\n",
      " [ -3.97900014e-01]\n",
      " [ -4.56610240e-01]\n",
      " [ -5.34547854e-01]\n",
      " [ -2.31893393e-01]\n",
      " [ -4.16098780e-01]\n",
      " [  3.98584626e+00]\n",
      " [ -9.29632797e-01]\n",
      " [ -1.23440203e+00]\n",
      " [  3.86785957e+00]\n",
      " [ -8.75316480e-01]\n",
      " [ -3.24947254e-01]\n",
      " [  4.14937520e-01]\n",
      " [ -3.33094930e-01]\n",
      " [  6.28431408e-02]\n",
      " [ -8.67650729e-01]\n",
      " [ -2.37101019e-01]\n",
      " [ -2.84811307e-01]\n",
      " [ -3.62626339e-01]\n",
      " [  7.30053591e-01]\n",
      " [ -4.51523225e-01]\n",
      " [  5.17453780e-01]\n",
      " [ -3.31898270e-01]\n",
      " [ -3.72809415e-02]\n",
      " [ -5.23410902e-01]\n",
      " [ -1.26053201e+00]\n",
      " [ -1.16447490e-01]\n",
      " [ -9.59800965e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -9.48668586e-01]\n",
      " [ -6.00882194e-01]\n",
      " [  9.73935653e-01]\n",
      " [  1.18224144e+00]\n",
      " [ -9.74568594e-01]\n",
      " [ -7.67161164e-01]\n",
      " [ -4.16565490e-01]\n",
      " [ -8.98756736e-01]\n",
      " [ -3.37349694e-01]\n",
      " [ -4.12860530e-01]\n",
      " [ -3.68746767e-01]\n",
      " [ -1.68159542e-01]\n",
      " [  1.92301567e-01]\n",
      " [  1.05530931e-01]\n",
      " [ -1.59063787e-01]\n",
      " [ -6.83366840e-01]\n",
      " [ -2.12074179e-01]\n",
      " [  3.95296574e-01]\n",
      " [ -8.42420879e-01]\n",
      " [  2.28293156e+00]\n",
      " [ -5.34185572e-01]\n",
      " [ -1.33974102e-01]\n",
      " [  9.21208793e-01]\n",
      " [ -5.34634051e-01]\n",
      " [ -1.29854249e+00]\n",
      " [ -3.30427285e-01]\n",
      " [ -4.27690290e-02]\n",
      " [ -3.73078602e-01]\n",
      " [ -3.97816970e-01]\n",
      " [  2.72382864e-01]\n",
      " [ -1.83484190e-01]\n",
      " [  2.55632633e-01]\n",
      " [ -2.62672076e-01]\n",
      " [  1.91603491e+00]\n",
      " [ -4.26451049e-01]\n",
      " [ -6.21766856e-01]\n",
      " [ -5.14239902e-01]\n",
      " [ -1.85865461e-01]\n",
      " [ -1.14771458e-01]\n",
      " [ -1.65700751e-01]\n",
      " [ -3.48128590e-01]\n",
      " [  1.19635560e+00]\n",
      " [ -5.38909501e-01]\n",
      " [ -1.33499561e-02]\n",
      " [ -1.02150761e+00]\n",
      " [ -5.34547854e-01]\n",
      " [  1.89572092e-01]\n",
      " [ -2.44857429e-01]\n",
      " [ -3.63485717e-01]\n",
      " [  7.73519800e-02]\n",
      " [  9.23726562e-01]\n",
      " [ -5.46332694e-01]\n",
      " [  2.22331935e+00]\n",
      " [ -4.16862372e-01]\n",
      " [  4.34606566e-01]\n",
      " [ -1.35675954e-01]\n",
      " [ -7.25707347e-01]\n",
      " [  9.67704094e+00]\n",
      " [ -1.05073702e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -1.95676801e-01]\n",
      " [ -6.71305048e-01]\n",
      " [  7.05472706e-01]\n",
      " [ -2.92693412e-01]\n",
      " [  8.28951723e-02]\n",
      " [ -2.82398432e-01]\n",
      " [ -4.03811904e-01]\n",
      " [  5.38874403e-01]\n",
      " [ -3.70140492e-01]\n",
      " [ -1.19546532e-01]\n",
      " [ -2.71537564e-01]\n",
      " [ -3.84396794e-01]\n",
      " [ -5.83342831e-01]\n",
      " [ -5.23863564e-01]\n",
      " [ -7.63141630e-01]\n",
      " [ -6.81855768e-01]\n",
      " [ -1.60699377e+00]\n",
      " [  1.93719875e-01]\n",
      " [  6.23194131e-01]\n",
      " [ -2.48563898e-01]\n",
      " [  9.99652527e-01]\n",
      " [ -4.70718732e-02]\n",
      " [  5.58371328e-01]\n",
      " [  5.38983469e-01]\n",
      " [ -5.23863564e-01]\n",
      " [ -1.60627798e-01]\n",
      " [ -7.04887133e-01]\n",
      " [ -2.62672076e-01]\n",
      " [  4.49286546e-01]\n",
      " [ -5.22901335e-01]\n",
      " [ -2.01114710e-01]\n",
      " [ -1.90094576e-01]\n",
      " [ -7.97340570e-01]\n",
      " [ -1.84446515e-01]\n",
      " [ -5.24376643e-01]\n",
      " [ -6.93573635e-01]\n",
      " [ -2.40478693e-01]\n",
      " [  1.52317237e+00]\n",
      " [ -5.34547854e-01]\n",
      " [  1.89982808e-01]\n",
      " [ -2.43198011e-01]\n",
      " [  3.74038752e+00]\n",
      " [ -6.90644383e-01]\n",
      " [ -1.04111473e-01]\n",
      " [  7.17012278e-01]\n",
      " [  8.84327508e-01]\n",
      " [  3.68607431e+00]\n",
      " [ -5.23863564e-01]\n",
      " [ -2.70053636e-01]\n",
      " [ -5.38482185e-01]\n",
      " [ -7.34591490e-01]\n",
      " [ -7.55472761e-02]\n",
      " [ -1.01717785e-01]\n",
      " [  9.23726562e-01]\n",
      " [ -5.17905372e-02]\n",
      " [ -4.64986755e-01]\n",
      " [  1.86427818e-01]\n",
      " [ -5.71068553e-02]\n",
      " [  4.79918383e-01]\n",
      " [  4.24408633e-01]\n",
      " [ -6.70698212e-01]\n",
      " [ -3.74766673e-01]\n",
      " [ -9.70581781e-01]\n",
      " [  4.11785441e+00]\n",
      " [ -5.04105820e-01]\n",
      " [  8.89689329e-01]\n",
      " [ -1.87283398e-01]\n",
      " [ -3.67038287e-01]\n",
      " [ -5.03463630e-01]\n",
      " [  6.05773211e-01]\n",
      " [ -9.84833503e-01]\n",
      " [ -1.47265660e-01]\n",
      " [ -5.34185572e-01]\n",
      " [ -8.56688077e-02]\n",
      " [ -4.59265871e-01]\n",
      " [  1.10838470e+00]\n",
      " [ -6.72512964e-01]\n",
      " [ -2.99040025e-01]\n",
      " [ -8.88452527e-01]\n",
      " [ -4.90088419e-01]\n",
      " [  2.24349477e+00]\n",
      " [ -7.81616207e-01]\n",
      " [ -4.88008415e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -5.81889790e-01]\n",
      " [ -2.10363023e-01]\n",
      " [  1.46235002e+00]\n",
      " [ -7.79999789e-02]\n",
      " [ -6.00207275e-01]\n",
      " [  1.04006755e+00]\n",
      " [ -2.48197434e-01]\n",
      " [  7.91610956e-01]\n",
      " [ -4.68269998e-02]\n",
      " [ -5.52265126e-01]\n",
      " [  5.94133188e-01]\n",
      " [  9.40702438e-01]\n",
      " [  9.45884874e-01]\n",
      " [  2.58857039e+00]\n",
      " [ -1.69108829e-01]\n",
      " [ -3.73312201e-01]\n",
      " [  7.69819188e-01]\n",
      " [ -1.30773107e-01]\n",
      " [ -1.36628093e-01]\n",
      " [  3.44444133e-01]\n",
      " [ -5.54642246e-01]\n",
      " [  4.77457114e-01]\n",
      " [ -9.51233984e-01]\n",
      " [  3.55160770e-01]\n",
      " [  1.61584235e-01]\n",
      " [ -3.10844888e-01]\n",
      " [  3.17189999e-01]\n",
      " [ -4.29074420e-01]\n",
      " [ -4.21355493e-01]\n",
      " [ -6.62024232e-01]\n",
      " [ -3.77716701e-01]\n",
      " [ -3.43506648e-01]\n",
      " [  5.99609617e-01]\n",
      " [  7.18555213e-01]\n",
      " [ -3.24229441e-01]\n",
      " [  1.00928887e+00]\n",
      " [ -4.22950139e-01]\n",
      " [ -2.76863381e-01]\n",
      " [ -5.20931701e-01]\n",
      " [  1.56720982e-02]\n",
      " [ -1.57212161e-01]\n",
      " [  1.04910297e+00]\n",
      " [  1.04910297e+00]\n",
      " [  6.67157760e-01]\n",
      " [ -1.51691586e-01]\n",
      " [ -5.03910869e-01]\n",
      " [ -2.87185389e-01]\n",
      " [  9.64810303e+00]\n",
      " [ -1.54579787e-01]\n",
      " [ -7.80060673e-02]\n",
      " [  3.31717191e-01]\n",
      " [ -7.05603798e-01]\n",
      " [  1.98679648e-01]\n",
      " [  2.43646516e-01]\n",
      " [  1.68502914e-01]\n",
      " [ -6.01720183e-01]\n",
      " [ -1.94883693e-01]\n",
      " [  1.05838321e+00]\n",
      " [ -1.43292038e-01]\n",
      " [  3.15107867e-01]\n",
      " [ -1.29888570e+00]\n",
      " [  3.42089765e-01]\n",
      " [ -1.57590602e+00]\n",
      " [  4.94317896e+00]\n",
      " [ -1.81875738e-01]\n",
      " [  4.91240027e+00]\n",
      " [  7.12679115e-01]\n",
      " [  7.71324100e-01]\n",
      " [ -2.31122673e-01]\n",
      " [ -5.79324393e-01]\n",
      " [ -5.23410902e-01]\n",
      " [ -1.50570247e-01]\n",
      " [  3.29689542e+00]\n",
      " [ -2.60970568e-01]\n",
      " [  1.86140139e+00]\n",
      " [ -3.98799647e-01]\n",
      " [ -5.79965332e-01]\n",
      " [  6.26116579e-01]\n",
      " [ -6.40881758e-01]\n",
      " [  7.52008234e-01]\n",
      " [ -4.15794770e-01]\n",
      " [ -7.12850842e-01]\n",
      " [ -4.95440350e-01]\n",
      " [  5.82888731e-01]\n",
      " [ -5.20563609e-01]\n",
      " [ -2.42852862e-01]\n",
      " [ -9.17889904e-01]\n",
      " [ -6.83366840e-01]\n",
      " [ -2.47198155e-01]\n",
      " [ -6.29210724e-02]\n",
      " [ -2.87956109e-01]\n",
      " [ -5.05573984e-01]\n",
      " [  7.46773937e-01]\n",
      " [ -4.52433383e-01]\n",
      " [ -3.03336318e-01]\n",
      " [ -5.33156368e-01]\n",
      " [ -2.83201345e-01]\n",
      " [ -1.76978855e-01]\n",
      " [  4.38724326e-01]\n",
      " [  5.38152021e-01]\n",
      " [ -4.27225656e-01]\n",
      " [ -1.00150969e+00]\n",
      " [ -8.74540773e-01]\n",
      " [  9.47172336e-02]\n",
      " [  2.93322648e-01]\n",
      " [ -1.74220042e-01]\n",
      " [  3.67979864e+00]\n",
      " [ -5.20313670e-01]\n",
      " [ -2.46084698e-01]\n",
      " [  2.24932790e-01]\n",
      " [  2.47998130e-01]\n",
      " [ -1.38864598e-01]\n",
      " [ -8.47039733e-01]\n",
      " [ -2.74702239e-01]\n",
      " [  6.22467340e-01]\n",
      " [ -1.50910446e+00]\n",
      " [ -5.17767027e-01]\n",
      " [ -1.38864598e-01]\n",
      " [ -4.72212961e-02]\n",
      " [ -4.47344173e-01]\n",
      " [ -3.66068108e-01]\n",
      " [  1.80073337e+00]\n",
      " [ -2.18456558e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -2.70408237e-01]\n",
      " [ -1.39787255e-01]\n",
      " [ -7.85572118e-01]\n",
      " [ -1.30262344e+00]\n",
      " [ -7.97340570e-01]\n",
      " [ -9.45781899e-01]\n",
      " [  2.76626796e-02]\n",
      " [ -6.39919529e-01]\n",
      " [ -5.32709593e-01]\n",
      " [  1.12641757e+00]\n",
      " [ -5.20976876e-01]\n",
      " [  1.63375834e-01]\n",
      " [ -7.85554291e-01]\n",
      " [  1.84359096e-01]\n",
      " [ -2.90732092e-01]\n",
      " [ -5.20931701e-01]\n",
      " [  3.45380145e-02]\n",
      " [ -6.88172072e-01]\n",
      " [ -2.86215831e-01]\n",
      " [ -3.34486416e-01]\n",
      " [  1.94674900e+00]\n",
      " [ -1.29307931e-01]\n",
      " [ -1.42676737e+00]\n",
      " [ -5.08777627e-01]\n",
      " [ -1.69464222e-01]\n",
      " [ -1.60111746e+00]\n",
      " [ -4.88008415e-01]\n",
      " [ -5.17767027e-01]\n",
      " [  4.77457114e-01]\n",
      " [ -5.16484328e-01]\n",
      " [  5.73742445e-01]\n",
      " [ -1.78137387e-01]\n",
      " [ -5.23863564e-01]\n",
      " [  3.21800702e-01]\n",
      " [ -9.55837732e-02]\n",
      " [ -2.64245996e-02]\n",
      " [  6.23412000e-01]\n",
      " [ -2.46084698e-01]\n",
      " [ -2.52040543e-01]\n",
      " [  1.95490701e+00]\n",
      " [ -9.99896997e-01]\n",
      " [  1.00961893e+00]\n",
      " [  4.63998848e-01]\n",
      " [ -5.34547854e-01]\n",
      " [ -1.23072339e-01]\n",
      " [  6.64177796e-01]\n",
      " [ -1.56543800e-01]\n",
      " [ -5.39277397e-01]\n",
      " [ -3.44746534e-01]\n",
      " [ -3.55258672e-01]\n",
      " [ -3.44219573e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -3.62070117e-01]\n",
      " [ -4.91779248e-01]\n",
      " [ -2.01114710e-01]\n",
      " [ -8.68654674e-02]\n",
      " [ -3.31290018e-01]\n",
      " [  3.75297989e+00]\n",
      " [ -6.13203150e-01]\n",
      " [ -8.95320493e-01]\n",
      " [  1.06375236e-01]\n",
      " [ -5.32709593e-01]\n",
      " [ -1.12378245e+00]\n",
      " [  6.10225572e-01]\n",
      " [ -3.28924030e-01]\n",
      " [  2.33057134e-01]\n",
      " [  7.71324100e-01]\n",
      " [ -2.46084698e-01]\n",
      " [ -2.76410719e-01]\n",
      " [ -2.98684632e-01]\n",
      " [ -6.00466867e-01]\n",
      " [ -6.03738385e-01]\n",
      " [  4.58432377e-01]\n",
      " [  7.88207450e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -8.76076678e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -5.73316587e-01]\n",
      " [ -2.28188433e-01]\n",
      " [  5.38052251e-01]\n",
      " [  1.32128262e+00]\n",
      " [  3.32993410e+00]\n",
      " [ -5.23863564e-01]\n",
      " [  2.34616575e+00]\n",
      " [ -6.10935805e-01]\n",
      " [  2.81137420e-01]\n",
      " [ -2.41788085e-01]\n",
      " [  1.44925935e+00]\n",
      " [ -2.05821233e-01]\n",
      " [  1.04910297e+00]\n",
      " [ -2.30503380e-01]\n",
      " [ -4.67011236e-02]\n",
      " [ -2.46084698e-01]\n",
      " [ -9.40999554e-01]\n",
      " [  7.71324100e-01]\n",
      " [ -1.01170363e+00]\n",
      " [ -6.69798452e-02]\n",
      " [ -6.83755048e-01]\n",
      " [  3.61788571e-03]\n",
      " [ -5.38290208e-01]\n",
      " [ -2.52085097e-01]\n",
      " [ -2.13998638e-01]\n",
      " [ -2.45315079e-01]\n",
      " [ -7.73072324e-02]\n",
      " [  3.25563596e+00]\n",
      " [  8.41567359e-01]\n",
      " [  1.52761015e+00]\n",
      " [ -4.88379830e-01]\n",
      " [ -4.28595653e-01]\n",
      " [  1.09227081e+00]\n",
      " [ -2.12545596e-01]\n",
      " [ -3.67334914e-01]\n",
      " [ -5.20867102e-01]\n",
      " [ -2.25940495e-01]\n",
      " [ -5.24290446e-01]\n",
      " [ -5.20931701e-01]\n",
      " [ -2.87761985e-01]\n",
      " [ -4.60464425e-01]\n",
      " [ -5.17767027e-01]\n",
      " [  1.99771645e+00]\n",
      " [ -1.16447490e-01]\n",
      " [  7.89125650e-02]\n",
      " [  5.87138421e-02]\n",
      " [  2.37506532e+00]\n",
      " [ -2.43433103e-01]\n",
      " [  1.01735559e+00]\n",
      " [ -5.23863564e-01]\n",
      " [ -4.92122652e-01]\n",
      " [ -1.54066708e-01]\n",
      " [  9.32818451e-01]\n",
      " [ -5.33671822e-01]\n",
      " [ -1.09369651e+00]\n",
      " [ -2.08176703e-01]\n",
      " [  8.87097985e-01]\n",
      " [ -3.49410619e-01]\n",
      " [ -2.46427435e-01]\n",
      " [ -6.52545539e-01]\n",
      " [ -7.85909684e-01]\n",
      " [ -3.20546494e-01]\n",
      " [  6.80562148e-01]\n",
      " [  7.84875743e-01]\n",
      " [ -5.35192986e-01]\n",
      " [ -9.42359622e-02]\n",
      " [ -7.09221556e-01]\n",
      " [ -2.69734068e-01]\n",
      " [  7.79807702e-01]\n",
      " [  4.91657938e-01]\n",
      " [ -5.02948640e-01]\n",
      " [ -6.74760516e-01]\n",
      " [  4.51167376e-01]\n",
      " [  5.22512053e-01]\n",
      " [ -2.43324279e-01]\n",
      " [  3.43285839e-01]\n",
      " [  1.10209509e+00]\n",
      " [ -8.97372811e-01]\n",
      " [  1.50125979e+00]\n",
      " [ -1.10880730e-01]\n",
      " [  9.94617939e-01]\n",
      " [ -1.25688340e-01]\n",
      " [ -8.51074061e-01]\n",
      " [ -5.17767027e-01]\n",
      " [ -5.74280911e-02]\n",
      " [  1.01390023e+00]\n",
      " [ -4.25810056e-01]\n",
      " [ -5.37846187e-01]\n",
      " [ -5.50831199e-01]\n",
      " [  6.29546803e-02]\n",
      " [ -1.98040650e-01]\n",
      " [ -5.29430808e-01]\n",
      " [ -9.66347896e-02]\n",
      " [ -4.47493398e-01]\n",
      " [  1.03805363e-01]\n",
      " [ -6.83366840e-01]\n",
      " [ -1.03213915e+00]\n",
      " [  4.29805345e-01]\n",
      " [ -2.43433103e-01]\n",
      " [ -5.13596127e-01]\n",
      " [  1.60538521e+00]\n",
      " [  7.50768299e-01]\n",
      " [ -1.80266661e-01]\n",
      " [ -5.24206301e-01]\n",
      " [ -5.08009417e-01]\n",
      " [ -7.99413240e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\anaconda\\lib\\site-packages\\sklearn\\lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "lda = LDA(n_components=5)\n",
    "lda.fit(x_train,y_train)\n",
    "print(lda.coef_)\n",
    "x_train = lda.transform(x_train)\n",
    "x_test = lda.transform(x_test)\n",
    "print(x_train.shape)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(n_jobs=-1)\n",
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#gbm = GradientBoostingClassifier()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability=True,kernel=\"rbf\")\n",
    "svc_lin = SVC(probability=True,kernel=\"linear\")\n",
    "import lightgbm as lgb\n",
    "gbm = lgb.LGBMClassifier(objective=\"binary\",max_depth=30,n_jobs=-1)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 8 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "depth_ls = [10,15,20,25,30]\n",
    "num_ls = [2**30-1]\n",
    "lng_ls = [0.01,0.015,0.05,0.1,0.3]\n",
    "sub_sample_ls = [0.6,0.7,0.8,0.9,1.0]\n",
    "gamma_ls = [0,0.05,0.1,0.3,0.5]\n",
    "alpha_ls = [0,0.1,0.5]\n",
    "lambda_ls = [0.01,0.1]\n",
    "min_child_ls = [1,3,5,7]\n",
    "colsample_ls = [0.6,0.7,0.8,0.9,1.0]\n",
    "lgb_params = {\"max_depth\":depth_ls[4:],\n",
    "    \"subsample\":sub_sample_ls,\n",
    "    \"learning_rate\":lng_ls,\"min_split_gain\":gamma_ls,\n",
    "    \"lambda_l1\":alpha_ls,\"lambda_l2\":lambda_ls,\n",
    "    \"min_child_weight\":min_child_ls,\"colsample_bytree\":colsample_ls}\n",
    "pen_ls = [\"l1\",\"l2\"]\n",
    "c_ls = [0.001,0.01,0.1,1,10,100]\n",
    "lr_params = {\"penalty\":pen_ls,\"C\":c_ls}\n",
    "svc_params = {\"C\":c_ls,\"gamma\":gamma_ls}\n",
    "est_ls = [60,120,300,500,800]\n",
    "forest_params = {\"max_depth\":depth_ls[:4],\"n_estimators\":est_ls[:4]}\n",
    "P_ls = [2,3]\n",
    "N_neighbors = [2,4,8,16]\n",
    "knn_params = {\"p\":P_ls,\"n_neighbors\":N_neighbors}\n",
    "\n",
    "gs_lgb = GridSearchCV(estimator=gbm,cv=10,param_grid=lgb_params,n_jobs=-1,verbose=1)\n",
    "#gs.fit(x_train,y_train)\n",
    "gs_lr = GridSearchCV(estimator=lr,param_grid=lr_params,n_jobs=-1,cv=20,verbose=1)\n",
    "#gs1.fit(x_train,y_train)\n",
    "gs_svc = GridSearchCV(estimator=svc,param_grid=svc_params,n_jobs=-1,cv=20,verbose=1)\n",
    "#gs2.fit(x_train,y_train)\n",
    "gs_for = GridSearchCV(estimator=forest,param_grid=forest_params,cv=20,n_jobs=-1,verbose=1)\n",
    "#gs3.fit(x_train,y_train)\n",
    "gs4_knn = GridSearchCV(estimator=knn,param_grid=knn_params,cv=20,n_jobs=-1,verbose=1)\n",
    "gs4_knn.fit(x_train,y_train)\n",
    "gs_svc_lin = GridSearchCV(estimator=svc_lin,param_grid=svc_params,n_jobs=-1,cv=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package lightgbm:\n",
      "\n",
      "NAME\n",
      "    lightgbm - LightGBM, Light Gradient Boosting Machine.\n",
      "\n",
      "DESCRIPTION\n",
      "    Contributors: https://github.com/Microsoft/LightGBM/graphs/contributors\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    basic\n",
      "    callback\n",
      "    compat\n",
      "    engine\n",
      "    lib_lightgbm\n",
      "    libpath\n",
      "    plotting\n",
      "    sklearn\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        lightgbm.basic.Booster\n",
      "        lightgbm.basic.Dataset\n",
      "    sklearn.base.BaseEstimator(builtins.object)\n",
      "        lightgbm.sklearn.LGBMModel\n",
      "            lightgbm.sklearn.LGBMClassifier(lightgbm.sklearn.LGBMModel, sklearn.base.ClassifierMixin)\n",
      "            lightgbm.sklearn.LGBMRanker\n",
      "            lightgbm.sklearn.LGBMRegressor(lightgbm.sklearn.LGBMModel, sklearn.base.RegressorMixin)\n",
      "    \n",
      "    class Booster(builtins.object)\n",
      "     |  Booster in LightGBM.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, _)\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, params=None, train_set=None, model_file=None, silent=False)\n",
      "     |      Initialize the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params: dict or None, optional (default=None)\n",
      "     |          Parameters for Booster.\n",
      "     |      train_set : Dataset or None, optional (default=None)\n",
      "     |          Training dataset.\n",
      "     |      model_file : string or None, optional (default=None)\n",
      "     |          Path to the model file.\n",
      "     |      silent : bool, optional (default=False)\n",
      "     |          Whether to print messages during construction.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  add_valid(self, data, name)\n",
      "     |      Add validation data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : Dataset\n",
      "     |          Validation data.\n",
      "     |      name : string\n",
      "     |          Name of validation data.\n",
      "     |  \n",
      "     |  attr(self, key)\n",
      "     |      Get attribute string from the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key : string\n",
      "     |          The name of the attribute.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : string or None\n",
      "     |          The attribute value.\n",
      "     |          Returns None if attribute do not exist.\n",
      "     |  \n",
      "     |  current_iteration(self)\n",
      "     |      Get the index of the current iteration.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cur_iter : int\n",
      "     |          The index of the current iteration.\n",
      "     |  \n",
      "     |  dump_model(self, num_iteration=-1)\n",
      "     |      Dump Booster to json format.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      num_iteration: int, optional (default=-1)\n",
      "     |          Index of the iteration that should to dumped.\n",
      "     |          If <0, the best iteration (if exists) is dumped.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      json_repr : dict\n",
      "     |          Json format of Booster.\n",
      "     |  \n",
      "     |  eval(self, data, name, feval=None)\n",
      "     |      Evaluate for data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : Dataset\n",
      "     |          Data for the evaluating.\n",
      "     |      name : string\n",
      "     |          Name of the data.\n",
      "     |      feval : callable or None, optional (default=None)\n",
      "     |          Custom evaluation function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result: list\n",
      "     |          List with evaluation results.\n",
      "     |  \n",
      "     |  eval_train(self, feval=None)\n",
      "     |      Evaluate for training data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      feval : callable or None, optional (default=None)\n",
      "     |          Custom evaluation function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result: list\n",
      "     |          List with evaluation results.\n",
      "     |  \n",
      "     |  eval_valid(self, feval=None)\n",
      "     |      Evaluate for validation data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      feval : callable or None, optional (default=None)\n",
      "     |          Custom evaluation function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result: list\n",
      "     |          List with evaluation results.\n",
      "     |  \n",
      "     |  feature_importance(self, importance_type='split', iteration=-1)\n",
      "     |      Get feature importances.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      importance_type : string, optional (default=\"split\")\n",
      "     |          How the importance is calculated.\n",
      "     |          If \"split\", result contains numbers of times the feature is used in a model.\n",
      "     |          If \"gain\", result contains total gains of splits which use the feature.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : numpy array\n",
      "     |          Array with feature importances.\n",
      "     |  \n",
      "     |  feature_name(self)\n",
      "     |      Get names of features.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : list\n",
      "     |          List with names of features.\n",
      "     |  \n",
      "     |  free_dataset(self)\n",
      "     |      Free Booster's Datasets.\n",
      "     |  \n",
      "     |  free_network(self)\n",
      "     |      Free Network.\n",
      "     |  \n",
      "     |  get_leaf_output(self, tree_id, leaf_id)\n",
      "     |      Get the output of a leaf.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tree_id : int\n",
      "     |          The index of the tree.\n",
      "     |      leaf_id : int\n",
      "     |          The index of the leaf in the tree.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : float\n",
      "     |          The output of the leaf.\n",
      "     |  \n",
      "     |  num_feature(self)\n",
      "     |      Get number of features.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      num_feature : int\n",
      "     |          The number of features.\n",
      "     |  \n",
      "     |  predict(self, data, num_iteration=-1, raw_score=False, pred_leaf=False, pred_contrib=False, data_has_header=False, is_reshape=True, pred_parameter=None)\n",
      "     |      Make a prediction.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : string, numpy array or scipy.sparse\n",
      "     |          Data source for prediction.\n",
      "     |          If string, it represents the path to txt file.\n",
      "     |      num_iteration : int, optional (default=-1)\n",
      "     |          Iteration used for prediction.\n",
      "     |          If <0, the best iteration (if exists) is used for prediction.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      pred_leaf : bool, optional (default=False)\n",
      "     |          Whether to predict leaf index.\n",
      "     |      pred_contrib : bool, optional (default=False)\n",
      "     |          Whether to predict feature contributions.\n",
      "     |      data_has_header : bool, optional (default=False)\n",
      "     |          Whether the data has header.\n",
      "     |          Used only if data is string.\n",
      "     |      is_reshape : bool, optional (default=True)\n",
      "     |          If True, result is reshaped to [nrow, ncol].\n",
      "     |      pred_parameter: dict or None, optional (default=None)\n",
      "     |          Other parameters for the prediction.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : numpy array\n",
      "     |          Prediction result.\n",
      "     |  \n",
      "     |  reset_parameter(self, params)\n",
      "     |      Reset parameters of Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : dict\n",
      "     |          New parameters for Booster.\n",
      "     |  \n",
      "     |  rollback_one_iter(self)\n",
      "     |      Rollback one iteration.\n",
      "     |  \n",
      "     |  save_model(self, filename, num_iteration=-1)\n",
      "     |      Save Booster to file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : string\n",
      "     |          Filename to save Booster.\n",
      "     |      num_iteration: int, optional (default=-1)\n",
      "     |          Index of the iteration that should to saved.\n",
      "     |          If <0, the best iteration (if exists) is saved.\n",
      "     |  \n",
      "     |  set_attr(self, **kwargs)\n",
      "     |      Set the attribute of the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          The attributes to set.\n",
      "     |          Setting a value to None deletes an attribute.\n",
      "     |  \n",
      "     |  set_network(self, machines, local_listen_port=12400, listen_time_out=120, num_machines=1)\n",
      "     |      Set the network configuration.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      machines: list, set or string\n",
      "     |          Names of machines.\n",
      "     |      local_listen_port: int, optional (default=12400)\n",
      "     |          TCP listen port for local machines.\n",
      "     |      listen_time_out: int, optional (default=120)\n",
      "     |          Socket time-out in minutes.\n",
      "     |      num_machines: int, optional (default=1)\n",
      "     |          The number of machines for parallel learning application.\n",
      "     |  \n",
      "     |  set_train_data_name(self, name)\n",
      "     |      Set the name to the training Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      name: string\n",
      "     |          Name for training Dataset.\n",
      "     |  \n",
      "     |  update(self, train_set=None, fobj=None)\n",
      "     |      Update for one iteration.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      train_set : Dataset or None, optional (default=None)\n",
      "     |          Training data.\n",
      "     |          If None, last training data is used.\n",
      "     |      fobj : callable or None, optional (default=None)\n",
      "     |          Customized objective function.\n",
      "     |      \n",
      "     |          For multi-class task, the score is group by class_id first, then group by row_id.\n",
      "     |          If you want to get i-th row score in j-th class, the access way is score[j * num_data + i]\n",
      "     |          and you should group grad and hess in this way as well.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      is_finished : bool\n",
      "     |          Whether the update was successfully finished.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Dataset(builtins.object)\n",
      "     |  Dataset in LightGBM.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __init__(self, data, label=None, reference=None, weight=None, group=None, init_score=None, silent=False, feature_name='auto', categorical_feature='auto', params=None, free_raw_data=True)\n",
      "     |      Constract Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : string, numpy array or scipy.sparse\n",
      "     |          Data source of Dataset.\n",
      "     |          If string, it represents the path to txt file.\n",
      "     |      label : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Label of the data.\n",
      "     |      reference : Dataset or None, optional (default=None)\n",
      "     |          If this is Dataset for validation, training data should be used as reference.\n",
      "     |      weight : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Weight for each instance.\n",
      "     |      group : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Group/query size for Dataset.\n",
      "     |      init_score : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Init score for Dataset.\n",
      "     |      silent : bool, optional (default=False)\n",
      "     |          Whether to print messages during construction.\n",
      "     |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "     |          Feature names.\n",
      "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "     |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "     |          Categorical features.\n",
      "     |          If list of int, interpreted as indices.\n",
      "     |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "     |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "     |      params: dict or None, optional (default=None)\n",
      "     |          Other parameters.\n",
      "     |      free_raw_data: bool, optional (default=True)\n",
      "     |          If True, raw data is freed after constructing inner Dataset.\n",
      "     |  \n",
      "     |  construct(self)\n",
      "     |      Lazy init.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Dataset\n",
      "     |          Returns self.\n",
      "     |  \n",
      "     |  create_valid(self, data, label=None, weight=None, group=None, init_score=None, silent=False, params=None)\n",
      "     |      Create validation data align with current Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : string, numpy array or scipy.sparse\n",
      "     |          Data source of Dataset.\n",
      "     |          If string, it represents the path to txt file.\n",
      "     |      label : list or numpy 1-D array, optional (default=None)\n",
      "     |          Label of the training data.\n",
      "     |      weight : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Weight for each instance.\n",
      "     |      group : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Group/query size for Dataset.\n",
      "     |      init_score : list, numpy 1-D array or None, optional (default=None)\n",
      "     |          Init score for Dataset.\n",
      "     |      silent : bool, optional (default=False)\n",
      "     |          Whether to print messages during construction.\n",
      "     |      params: dict or None, optional (default=None)\n",
      "     |          Other parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Dataset\n",
      "     |          Returns self.\n",
      "     |  \n",
      "     |  get_field(self, field_name)\n",
      "     |      Get property from the Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field_name: string\n",
      "     |          The field name of the information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : numpy array\n",
      "     |          A numpy array with information from the Dataset.\n",
      "     |  \n",
      "     |  get_group(self)\n",
      "     |      Get the group of the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group : numpy array\n",
      "     |          Group size of each group.\n",
      "     |  \n",
      "     |  get_init_score(self)\n",
      "     |      Get the initial score of the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      init_score : numpy array\n",
      "     |          Init score of Booster.\n",
      "     |  \n",
      "     |  get_label(self)\n",
      "     |      Get the label of the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      label : numpy array\n",
      "     |          The label information from the Dataset.\n",
      "     |  \n",
      "     |  get_ref_chain(self, ref_limit=100)\n",
      "     |      Get a chain of Dataset objects, starting with r, then going to r.reference if exists,\n",
      "     |      then to r.reference.reference, etc. until we hit ``ref_limit`` or a reference loop.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ref_limit : int, optional (default=100)\n",
      "     |          The limit number of references.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ref_chain : set of Dataset\n",
      "     |          Chain of references of the Datasets.\n",
      "     |  \n",
      "     |  get_weight(self)\n",
      "     |      Get the weight of the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      weight : numpy array\n",
      "     |          Weight for each data point from the Dataset.\n",
      "     |  \n",
      "     |  num_data(self)\n",
      "     |      Get the number of rows in the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      number_of_rows : int\n",
      "     |          The number of rows in the Dataset.\n",
      "     |  \n",
      "     |  num_feature(self)\n",
      "     |      Get the number of columns (features) in the Dataset.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      number_of_columns : int\n",
      "     |          The number of columns (features) in the Dataset.\n",
      "     |  \n",
      "     |  save_binary(self, filename)\n",
      "     |      Save Dataset to binary file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      filename : string\n",
      "     |          Name of the output file.\n",
      "     |  \n",
      "     |  set_categorical_feature(self, categorical_feature)\n",
      "     |      Set categorical features.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      categorical_feature : list of int or strings\n",
      "     |          Names or indices of categorical features.\n",
      "     |  \n",
      "     |  set_feature_name(self, feature_name)\n",
      "     |      Set feature name.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      feature_name : list of strings\n",
      "     |          Feature names.\n",
      "     |  \n",
      "     |  set_field(self, field_name, data)\n",
      "     |      Set property into the Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field_name: string\n",
      "     |          The field name of the information.\n",
      "     |      data: list, numpy array or None\n",
      "     |          The array of data to be set.\n",
      "     |  \n",
      "     |  set_group(self, group)\n",
      "     |      Set group size of Dataset (used for ranking).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      group : list, numpy array or None\n",
      "     |          Group size of each group.\n",
      "     |  \n",
      "     |  set_init_score(self, init_score)\n",
      "     |      Set init score of Booster to start from.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      init_score : list, numpy array or None\n",
      "     |          Init score for Booster.\n",
      "     |  \n",
      "     |  set_label(self, label)\n",
      "     |      Set label of Dataset\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label: list, numpy array or None\n",
      "     |          The label information to be set into Dataset.\n",
      "     |  \n",
      "     |  set_reference(self, reference)\n",
      "     |      Set reference Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      reference : Dataset\n",
      "     |          Reference that is used as a template to consturct the current Dataset.\n",
      "     |  \n",
      "     |  set_weight(self, weight)\n",
      "     |      Set weight of each instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      weight : list, numpy array or None\n",
      "     |          Weight to be set for each data point.\n",
      "     |  \n",
      "     |  subset(self, used_indices, params=None)\n",
      "     |      Get subset of current Dataset.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      used_indices : list of int\n",
      "     |          Indices used to create the subset.\n",
      "     |      params: dict or None, optional (default=None)\n",
      "     |          Other parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      subset : Dataset\n",
      "     |          Subset of the current Dataset.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LGBMClassifier(LGBMModel, sklearn.base.ClassifierMixin)\n",
      "     |  LightGBM classifier.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LGBMClassifier\n",
      "     |      LGBMModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_metric='logloss', early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      "     |      Build a gradient boosting model from the training set (X, y).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input feature matrix.\n",
      "     |      y : array-like of shape = [n_samples]\n",
      "     |          The target values (class labels in classification, real numbers in regression).\n",
      "     |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Weights of training data.\n",
      "     |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Init score of training data.\n",
      "     |      group : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Group data of training data.\n",
      "     |      eval_set : list or None, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation sets for early-stopping.\n",
      "     |      eval_names: list of strings or None, optional (default=None)\n",
      "     |          Names of eval_set.\n",
      "     |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "     |          Weights of eval data.\n",
      "     |      eval_init_score : list of arrays or None, optional (default=None)\n",
      "     |          Init score of eval data.\n",
      "     |      eval_group : list of arrays or None, optional (default=None)\n",
      "     |          Group data of eval data.\n",
      "     |      eval_metric : string, list of strings, callable or None, optional (default=\"logloss\")\n",
      "     |          If string, it should be a built-in evaluation metric to use.\n",
      "     |          If callable, it should be a custom evaluation metric, see note for more details.\n",
      "     |      early_stopping_rounds : int or None, optional (default=None)\n",
      "     |          Activates early stopping. The model will train until the validation score stops improving.\n",
      "     |          Validation error needs to decrease at least every ``early_stopping_rounds`` round(s)\n",
      "     |          to continue training.\n",
      "     |      verbose : bool, optional (default=True)\n",
      "     |          If True and an evaluation set is used, writes the evaluation progress.\n",
      "     |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "     |          Feature names.\n",
      "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "     |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "     |          Categorical features.\n",
      "     |          If list of int, interpreted as indices.\n",
      "     |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "     |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "     |      callbacks : list of callback functions or None, optional (default=None)\n",
      "     |          List of callback functions that are applied at each iteration.\n",
      "     |          See Callbacks in Python API for more information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Custom eval function expects a callable with following functions:\n",
      "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "     |      ``func(y_true, y_pred, weight, group)``.\n",
      "     |      Returns (eval_name, eval_result, is_bigger_better) or\n",
      "     |      list of (eval_name, eval_result, is_bigger_better)\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)\n",
      "     |              The predicted values.\n",
      "     |          weight: array-like of shape = [n_samples]\n",
      "     |              The weight of samples.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          eval_name: str\n",
      "     |              The name of evaluation.\n",
      "     |          eval_result: float\n",
      "     |              The eval result.\n",
      "     |          is_bigger_better: bool\n",
      "     |              Is eval result bigger better, e.g. AUC is bigger_better.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "     |  \n",
      "     |  predict(self, X, raw_score=False, num_iteration=0)\n",
      "     |      Return the predicted value for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  predict_proba(self, X, raw_score=False, num_iteration=0)\n",
      "     |      Return the predicted probability for each class for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predicted_probability : array-like of shape = [n_samples, n_classes]\n",
      "     |          The predicted probability for each class for each sample.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |      Get the class label array.\n",
      "     |  \n",
      "     |  n_classes_\n",
      "     |      Get the number of classes.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  base_doc = 'Build a gradient boosting model from the trainin... access...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LGBMModel:\n",
      "     |  \n",
      "     |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=10, subsample_for_bin=200000, objective=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=1, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs)\n",
      "     |      Construct a gradient boosting model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      boosting_type : string, optional (default=\"gbdt\")\n",
      "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      "     |          'goss', Gradient-based One-Side Sampling.\n",
      "     |          'rf', Random Forest.\n",
      "     |      num_leaves : int, optional (default=31)\n",
      "     |          Maximum tree leaves for base learners.\n",
      "     |      max_depth : int, optional (default=-1)\n",
      "     |          Maximum tree depth for base learners, -1 means no limit.\n",
      "     |      learning_rate : float, optional (default=0.1)\n",
      "     |          Boosting learning rate.\n",
      "     |      n_estimators : int, optional (default=10)\n",
      "     |          Number of boosted trees to fit.\n",
      "     |      subsample_for_bin : int, optional (default=50000)\n",
      "     |          Number of samples for constructing bins.\n",
      "     |      objective : string, callable or None, optional (default=None)\n",
      "     |          Specify the learning task and the corresponding learning objective or\n",
      "     |          a custom objective function to be used (see note below).\n",
      "     |          default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      "     |      min_split_gain : float, optional (default=0.)\n",
      "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      "     |      min_child_weight : float, optional (default=1e-3)\n",
      "     |          Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
      "     |      min_child_samples : int, optional (default=20)\n",
      "     |          Minimum number of data need in a child(leaf).\n",
      "     |      subsample : float, optional (default=1.)\n",
      "     |          Subsample ratio of the training instance.\n",
      "     |      subsample_freq : int, optional (default=1)\n",
      "     |          Frequence of subsample, <=0 means no enable.\n",
      "     |      colsample_bytree : float, optional (default=1.)\n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |      reg_alpha : float, optional (default=0.)\n",
      "     |          L1 regularization term on weights.\n",
      "     |      reg_lambda : float, optional (default=0.)\n",
      "     |          L2 regularization term on weights.\n",
      "     |      random_state : int or None, optional (default=None)\n",
      "     |          Random number seed.\n",
      "     |          Will use default seeds in c++ code if set to None.\n",
      "     |      n_jobs : int, optional (default=-1)\n",
      "     |          Number of parallel threads.\n",
      "     |      silent : bool, optional (default=True)\n",
      "     |          Whether to print messages while running boosting.\n",
      "     |      **kwargs : other parameters\n",
      "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      "     |      \n",
      "     |          Note\n",
      "     |          ----\n",
      "     |          \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      n_features_ : int\n",
      "     |          The number of features of fitted model.\n",
      "     |      classes_ : array of shape = [n_classes]\n",
      "     |          The class label array (only for classification problem).\n",
      "     |      n_classes_ : int\n",
      "     |          The number of classes (only for classification problem).\n",
      "     |      best_score_ : dict or None\n",
      "     |          The best score of fitted model.\n",
      "     |      best_iteration_ : int or None\n",
      "     |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      "     |      objective_ : string or callable\n",
      "     |          The concrete objective used while fitting this model.\n",
      "     |      booster_ : Booster\n",
      "     |          The underlying Booster of this model.\n",
      "     |      evals_result_ : dict or None\n",
      "     |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      "     |      feature_importances_ : array of shape = [n_features]\n",
      "     |          The feature importances (the higher, the more important the feature).\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      A custom objective function can be provided for the ``objective``\n",
      "     |      parameter. In this case, it should have the signature\n",
      "     |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      "     |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The predicted values.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          grad: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the gradient for each sample point.\n",
      "     |          hess: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the second derivative for each sample point.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      "     |      and you should group grad and hess in this way as well.\n",
      "     |  \n",
      "     |  apply(self, X, num_iteration=0)\n",
      "     |      Return the predicted leaf every tree for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array-like of shape = [n_samples, n_trees]\n",
      "     |          The predicted leaf every tree for each sample.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from LGBMModel:\n",
      "     |  \n",
      "     |  best_iteration_\n",
      "     |      Get the best iteration of fitted model.\n",
      "     |  \n",
      "     |  best_score_\n",
      "     |      Get the best score of fitted model.\n",
      "     |  \n",
      "     |  booster_\n",
      "     |      Get the underlying lightgbm Booster of this model.\n",
      "     |  \n",
      "     |  evals_result_\n",
      "     |      Get the evaluation results.\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Get feature importances.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Feature importance in sklearn interface used to normalize to 1,\n",
      "     |      it's deprecated after 2.0.4 and same as Booster.feature_importance() now.\n",
      "     |  \n",
      "     |  n_features_\n",
      "     |      Get the number of features of fitted model.\n",
      "     |  \n",
      "     |  objective_\n",
      "     |      Get the concrete objective used while fitting this model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True labels for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of self.predict(X) wrt. y.\n",
      "    \n",
      "    class LGBMModel(sklearn.base.BaseEstimator)\n",
      "     |  Implementation of the scikit-learn API for LightGBM.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LGBMModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=10, subsample_for_bin=200000, objective=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=1, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs)\n",
      "     |      Construct a gradient boosting model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      boosting_type : string, optional (default=\"gbdt\")\n",
      "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      "     |          'goss', Gradient-based One-Side Sampling.\n",
      "     |          'rf', Random Forest.\n",
      "     |      num_leaves : int, optional (default=31)\n",
      "     |          Maximum tree leaves for base learners.\n",
      "     |      max_depth : int, optional (default=-1)\n",
      "     |          Maximum tree depth for base learners, -1 means no limit.\n",
      "     |      learning_rate : float, optional (default=0.1)\n",
      "     |          Boosting learning rate.\n",
      "     |      n_estimators : int, optional (default=10)\n",
      "     |          Number of boosted trees to fit.\n",
      "     |      subsample_for_bin : int, optional (default=50000)\n",
      "     |          Number of samples for constructing bins.\n",
      "     |      objective : string, callable or None, optional (default=None)\n",
      "     |          Specify the learning task and the corresponding learning objective or\n",
      "     |          a custom objective function to be used (see note below).\n",
      "     |          default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      "     |      min_split_gain : float, optional (default=0.)\n",
      "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      "     |      min_child_weight : float, optional (default=1e-3)\n",
      "     |          Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
      "     |      min_child_samples : int, optional (default=20)\n",
      "     |          Minimum number of data need in a child(leaf).\n",
      "     |      subsample : float, optional (default=1.)\n",
      "     |          Subsample ratio of the training instance.\n",
      "     |      subsample_freq : int, optional (default=1)\n",
      "     |          Frequence of subsample, <=0 means no enable.\n",
      "     |      colsample_bytree : float, optional (default=1.)\n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |      reg_alpha : float, optional (default=0.)\n",
      "     |          L1 regularization term on weights.\n",
      "     |      reg_lambda : float, optional (default=0.)\n",
      "     |          L2 regularization term on weights.\n",
      "     |      random_state : int or None, optional (default=None)\n",
      "     |          Random number seed.\n",
      "     |          Will use default seeds in c++ code if set to None.\n",
      "     |      n_jobs : int, optional (default=-1)\n",
      "     |          Number of parallel threads.\n",
      "     |      silent : bool, optional (default=True)\n",
      "     |          Whether to print messages while running boosting.\n",
      "     |      **kwargs : other parameters\n",
      "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      "     |      \n",
      "     |          Note\n",
      "     |          ----\n",
      "     |          \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      n_features_ : int\n",
      "     |          The number of features of fitted model.\n",
      "     |      classes_ : array of shape = [n_classes]\n",
      "     |          The class label array (only for classification problem).\n",
      "     |      n_classes_ : int\n",
      "     |          The number of classes (only for classification problem).\n",
      "     |      best_score_ : dict or None\n",
      "     |          The best score of fitted model.\n",
      "     |      best_iteration_ : int or None\n",
      "     |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      "     |      objective_ : string or callable\n",
      "     |          The concrete objective used while fitting this model.\n",
      "     |      booster_ : Booster\n",
      "     |          The underlying Booster of this model.\n",
      "     |      evals_result_ : dict or None\n",
      "     |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      "     |      feature_importances_ : array of shape = [n_features]\n",
      "     |          The feature importances (the higher, the more important the feature).\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      A custom objective function can be provided for the ``objective``\n",
      "     |      parameter. In this case, it should have the signature\n",
      "     |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      "     |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The predicted values.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          grad: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the gradient for each sample point.\n",
      "     |          hess: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the second derivative for each sample point.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      "     |      and you should group grad and hess in this way as well.\n",
      "     |  \n",
      "     |  apply(self, X, num_iteration=0)\n",
      "     |      Return the predicted leaf every tree for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array-like of shape = [n_samples, n_trees]\n",
      "     |          The predicted leaf every tree for each sample.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, init_score=None, group=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_group=None, eval_metric=None, early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      "     |      Build a gradient boosting model from the training set (X, y).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input feature matrix.\n",
      "     |      y : array-like of shape = [n_samples]\n",
      "     |          The target values (class labels in classification, real numbers in regression).\n",
      "     |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Weights of training data.\n",
      "     |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Init score of training data.\n",
      "     |      group : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Group data of training data.\n",
      "     |      eval_set : list or None, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation sets for early-stopping.\n",
      "     |      eval_names: list of strings or None, optional (default=None)\n",
      "     |          Names of eval_set.\n",
      "     |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "     |          Weights of eval data.\n",
      "     |      eval_init_score : list of arrays or None, optional (default=None)\n",
      "     |          Init score of eval data.\n",
      "     |      eval_group : list of arrays or None, optional (default=None)\n",
      "     |          Group data of eval data.\n",
      "     |      eval_metric : string, list of strings, callable or None, optional (default=None)\n",
      "     |          If string, it should be a built-in evaluation metric to use.\n",
      "     |          If callable, it should be a custom evaluation metric, see note for more details.\n",
      "     |      early_stopping_rounds : int or None, optional (default=None)\n",
      "     |          Activates early stopping. The model will train until the validation score stops improving.\n",
      "     |          Validation error needs to decrease at least every ``early_stopping_rounds`` round(s)\n",
      "     |          to continue training.\n",
      "     |      verbose : bool, optional (default=True)\n",
      "     |          If True and an evaluation set is used, writes the evaluation progress.\n",
      "     |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "     |          Feature names.\n",
      "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "     |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "     |          Categorical features.\n",
      "     |          If list of int, interpreted as indices.\n",
      "     |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "     |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "     |      callbacks : list of callback functions or None, optional (default=None)\n",
      "     |          List of callback functions that are applied at each iteration.\n",
      "     |          See Callbacks in Python API for more information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Custom eval function expects a callable with following functions:\n",
      "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "     |      ``func(y_true, y_pred, weight, group)``.\n",
      "     |      Returns (eval_name, eval_result, is_bigger_better) or\n",
      "     |      list of (eval_name, eval_result, is_bigger_better)\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)\n",
      "     |              The predicted values.\n",
      "     |          weight: array-like of shape = [n_samples]\n",
      "     |              The weight of samples.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          eval_name: str\n",
      "     |              The name of evaluation.\n",
      "     |          eval_result: float\n",
      "     |              The eval result.\n",
      "     |          is_bigger_better: bool\n",
      "     |              Is eval result bigger better, e.g. AUC is bigger_better.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  predict(self, X, raw_score=False, num_iteration=0)\n",
      "     |      Return the predicted value for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  best_iteration_\n",
      "     |      Get the best iteration of fitted model.\n",
      "     |  \n",
      "     |  best_score_\n",
      "     |      Get the best score of fitted model.\n",
      "     |  \n",
      "     |  booster_\n",
      "     |      Get the underlying lightgbm Booster of this model.\n",
      "     |  \n",
      "     |  evals_result_\n",
      "     |      Get the evaluation results.\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Get feature importances.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Feature importance in sklearn interface used to normalize to 1,\n",
      "     |      it's deprecated after 2.0.4 and same as Booster.feature_importance() now.\n",
      "     |  \n",
      "     |  n_features_\n",
      "     |      Get the number of features of fitted model.\n",
      "     |  \n",
      "     |  objective_\n",
      "     |      Get the concrete objective used while fitting this model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LGBMRanker(LGBMModel)\n",
      "     |  LightGBM ranker.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LGBMRanker\n",
      "     |      LGBMModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, init_score=None, group=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_group=None, eval_metric='ndcg', eval_at=[1], early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      "     |      Build a gradient boosting model from the training set (X, y).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input feature matrix.\n",
      "     |      y : array-like of shape = [n_samples]\n",
      "     |          The target values (class labels in classification, real numbers in regression).\n",
      "     |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Weights of training data.\n",
      "     |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Init score of training data.\n",
      "     |      group : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Group data of training data.\n",
      "     |      eval_set : list or None, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation sets for early-stopping.\n",
      "     |      eval_names: list of strings or None, optional (default=None)\n",
      "     |          Names of eval_set.\n",
      "     |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "     |          Weights of eval data.\n",
      "     |      eval_init_score : list of arrays or None, optional (default=None)\n",
      "     |          Init score of eval data.\n",
      "     |      eval_group : list of arrays or None, optional (default=None)\n",
      "     |          Group data of eval data.\n",
      "     |      eval_metric : string, list of strings, callable or None, optional (default=\"ndcg\")\n",
      "     |          If string, it should be a built-in evaluation metric to use.\n",
      "     |          If callable, it should be a custom evaluation metric, see note for more details.\n",
      "     |      eval_at : list of int, optional (default=[1])\n",
      "     |          The evaluation positions of NDCG.\n",
      "     |      early_stopping_rounds : int or None, optional (default=None)\n",
      "     |          Activates early stopping. The model will train until the validation score stops improving.\n",
      "     |          Validation error needs to decrease at least every ``early_stopping_rounds`` round(s)\n",
      "     |          to continue training.\n",
      "     |      verbose : bool, optional (default=True)\n",
      "     |          If True and an evaluation set is used, writes the evaluation progress.\n",
      "     |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "     |          Feature names.\n",
      "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "     |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "     |          Categorical features.\n",
      "     |          If list of int, interpreted as indices.\n",
      "     |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "     |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "     |      callbacks : list of callback functions or None, optional (default=None)\n",
      "     |          List of callback functions that are applied at each iteration.\n",
      "     |          See Callbacks in Python API for more information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Custom eval function expects a callable with following functions:\n",
      "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "     |      ``func(y_true, y_pred, weight, group)``.\n",
      "     |      Returns (eval_name, eval_result, is_bigger_better) or\n",
      "     |      list of (eval_name, eval_result, is_bigger_better)\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)\n",
      "     |              The predicted values.\n",
      "     |          weight: array-like of shape = [n_samples]\n",
      "     |              The weight of samples.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          eval_name: str\n",
      "     |              The name of evaluation.\n",
      "     |          eval_result: float\n",
      "     |              The eval result.\n",
      "     |          is_bigger_better: bool\n",
      "     |              Is eval result bigger better, e.g. AUC is bigger_better.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  base_doc = 'Build a gradient boosting model from the trainin... access...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LGBMModel:\n",
      "     |  \n",
      "     |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=10, subsample_for_bin=200000, objective=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=1, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs)\n",
      "     |      Construct a gradient boosting model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      boosting_type : string, optional (default=\"gbdt\")\n",
      "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      "     |          'goss', Gradient-based One-Side Sampling.\n",
      "     |          'rf', Random Forest.\n",
      "     |      num_leaves : int, optional (default=31)\n",
      "     |          Maximum tree leaves for base learners.\n",
      "     |      max_depth : int, optional (default=-1)\n",
      "     |          Maximum tree depth for base learners, -1 means no limit.\n",
      "     |      learning_rate : float, optional (default=0.1)\n",
      "     |          Boosting learning rate.\n",
      "     |      n_estimators : int, optional (default=10)\n",
      "     |          Number of boosted trees to fit.\n",
      "     |      subsample_for_bin : int, optional (default=50000)\n",
      "     |          Number of samples for constructing bins.\n",
      "     |      objective : string, callable or None, optional (default=None)\n",
      "     |          Specify the learning task and the corresponding learning objective or\n",
      "     |          a custom objective function to be used (see note below).\n",
      "     |          default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      "     |      min_split_gain : float, optional (default=0.)\n",
      "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      "     |      min_child_weight : float, optional (default=1e-3)\n",
      "     |          Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
      "     |      min_child_samples : int, optional (default=20)\n",
      "     |          Minimum number of data need in a child(leaf).\n",
      "     |      subsample : float, optional (default=1.)\n",
      "     |          Subsample ratio of the training instance.\n",
      "     |      subsample_freq : int, optional (default=1)\n",
      "     |          Frequence of subsample, <=0 means no enable.\n",
      "     |      colsample_bytree : float, optional (default=1.)\n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |      reg_alpha : float, optional (default=0.)\n",
      "     |          L1 regularization term on weights.\n",
      "     |      reg_lambda : float, optional (default=0.)\n",
      "     |          L2 regularization term on weights.\n",
      "     |      random_state : int or None, optional (default=None)\n",
      "     |          Random number seed.\n",
      "     |          Will use default seeds in c++ code if set to None.\n",
      "     |      n_jobs : int, optional (default=-1)\n",
      "     |          Number of parallel threads.\n",
      "     |      silent : bool, optional (default=True)\n",
      "     |          Whether to print messages while running boosting.\n",
      "     |      **kwargs : other parameters\n",
      "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      "     |      \n",
      "     |          Note\n",
      "     |          ----\n",
      "     |          \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      n_features_ : int\n",
      "     |          The number of features of fitted model.\n",
      "     |      classes_ : array of shape = [n_classes]\n",
      "     |          The class label array (only for classification problem).\n",
      "     |      n_classes_ : int\n",
      "     |          The number of classes (only for classification problem).\n",
      "     |      best_score_ : dict or None\n",
      "     |          The best score of fitted model.\n",
      "     |      best_iteration_ : int or None\n",
      "     |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      "     |      objective_ : string or callable\n",
      "     |          The concrete objective used while fitting this model.\n",
      "     |      booster_ : Booster\n",
      "     |          The underlying Booster of this model.\n",
      "     |      evals_result_ : dict or None\n",
      "     |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      "     |      feature_importances_ : array of shape = [n_features]\n",
      "     |          The feature importances (the higher, the more important the feature).\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      A custom objective function can be provided for the ``objective``\n",
      "     |      parameter. In this case, it should have the signature\n",
      "     |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      "     |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The predicted values.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          grad: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the gradient for each sample point.\n",
      "     |          hess: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the second derivative for each sample point.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      "     |      and you should group grad and hess in this way as well.\n",
      "     |  \n",
      "     |  apply(self, X, num_iteration=0)\n",
      "     |      Return the predicted leaf every tree for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array-like of shape = [n_samples, n_trees]\n",
      "     |          The predicted leaf every tree for each sample.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  predict(self, X, raw_score=False, num_iteration=0)\n",
      "     |      Return the predicted value for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from LGBMModel:\n",
      "     |  \n",
      "     |  best_iteration_\n",
      "     |      Get the best iteration of fitted model.\n",
      "     |  \n",
      "     |  best_score_\n",
      "     |      Get the best score of fitted model.\n",
      "     |  \n",
      "     |  booster_\n",
      "     |      Get the underlying lightgbm Booster of this model.\n",
      "     |  \n",
      "     |  evals_result_\n",
      "     |      Get the evaluation results.\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Get feature importances.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Feature importance in sklearn interface used to normalize to 1,\n",
      "     |      it's deprecated after 2.0.4 and same as Booster.feature_importance() now.\n",
      "     |  \n",
      "     |  n_features_\n",
      "     |      Get the number of features of fitted model.\n",
      "     |  \n",
      "     |  objective_\n",
      "     |      Get the concrete objective used while fitting this model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LGBMRegressor(LGBMModel, sklearn.base.RegressorMixin)\n",
      "     |  LightGBM regressor.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LGBMRegressor\n",
      "     |      LGBMModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None, init_score=None, eval_set=None, eval_names=None, eval_sample_weight=None, eval_init_score=None, eval_metric='l2', early_stopping_rounds=None, verbose=True, feature_name='auto', categorical_feature='auto', callbacks=None)\n",
      "     |      Build a gradient boosting model from the training set (X, y).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input feature matrix.\n",
      "     |      y : array-like of shape = [n_samples]\n",
      "     |          The target values (class labels in classification, real numbers in regression).\n",
      "     |      sample_weight : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Weights of training data.\n",
      "     |      init_score : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Init score of training data.\n",
      "     |      group : array-like of shape = [n_samples] or None, optional (default=None)\n",
      "     |          Group data of training data.\n",
      "     |      eval_set : list or None, optional (default=None)\n",
      "     |          A list of (X, y) tuple pairs to use as a validation sets for early-stopping.\n",
      "     |      eval_names: list of strings or None, optional (default=None)\n",
      "     |          Names of eval_set.\n",
      "     |      eval_sample_weight : list of arrays or None, optional (default=None)\n",
      "     |          Weights of eval data.\n",
      "     |      eval_init_score : list of arrays or None, optional (default=None)\n",
      "     |          Init score of eval data.\n",
      "     |      eval_group : list of arrays or None, optional (default=None)\n",
      "     |          Group data of eval data.\n",
      "     |      eval_metric : string, list of strings, callable or None, optional (default=\"l2\")\n",
      "     |          If string, it should be a built-in evaluation metric to use.\n",
      "     |          If callable, it should be a custom evaluation metric, see note for more details.\n",
      "     |      early_stopping_rounds : int or None, optional (default=None)\n",
      "     |          Activates early stopping. The model will train until the validation score stops improving.\n",
      "     |          Validation error needs to decrease at least every ``early_stopping_rounds`` round(s)\n",
      "     |          to continue training.\n",
      "     |      verbose : bool, optional (default=True)\n",
      "     |          If True and an evaluation set is used, writes the evaluation progress.\n",
      "     |      feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "     |          Feature names.\n",
      "     |          If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "     |      categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "     |          Categorical features.\n",
      "     |          If list of int, interpreted as indices.\n",
      "     |          If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "     |          If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "     |      callbacks : list of callback functions or None, optional (default=None)\n",
      "     |          List of callback functions that are applied at each iteration.\n",
      "     |          See Callbacks in Python API for more information.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns self.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Custom eval function expects a callable with following functions:\n",
      "     |      ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or\n",
      "     |      ``func(y_true, y_pred, weight, group)``.\n",
      "     |      Returns (eval_name, eval_result, is_bigger_better) or\n",
      "     |      list of (eval_name, eval_result, is_bigger_better)\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class)\n",
      "     |              The predicted values.\n",
      "     |          weight: array-like of shape = [n_samples]\n",
      "     |              The weight of samples.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          eval_name: str\n",
      "     |              The name of evaluation.\n",
      "     |          eval_result: float\n",
      "     |              The eval result.\n",
      "     |          is_bigger_better: bool\n",
      "     |              Is eval result bigger better, e.g. AUC is bigger_better.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  base_doc = 'Build a gradient boosting model from the trainin... access...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LGBMModel:\n",
      "     |  \n",
      "     |  __init__(self, boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=10, subsample_for_bin=200000, objective=None, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, subsample_freq=1, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, random_state=None, n_jobs=-1, silent=True, **kwargs)\n",
      "     |      Construct a gradient boosting model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      boosting_type : string, optional (default=\"gbdt\")\n",
      "     |          'gbdt', traditional Gradient Boosting Decision Tree.\n",
      "     |          'dart', Dropouts meet Multiple Additive Regression Trees.\n",
      "     |          'goss', Gradient-based One-Side Sampling.\n",
      "     |          'rf', Random Forest.\n",
      "     |      num_leaves : int, optional (default=31)\n",
      "     |          Maximum tree leaves for base learners.\n",
      "     |      max_depth : int, optional (default=-1)\n",
      "     |          Maximum tree depth for base learners, -1 means no limit.\n",
      "     |      learning_rate : float, optional (default=0.1)\n",
      "     |          Boosting learning rate.\n",
      "     |      n_estimators : int, optional (default=10)\n",
      "     |          Number of boosted trees to fit.\n",
      "     |      subsample_for_bin : int, optional (default=50000)\n",
      "     |          Number of samples for constructing bins.\n",
      "     |      objective : string, callable or None, optional (default=None)\n",
      "     |          Specify the learning task and the corresponding learning objective or\n",
      "     |          a custom objective function to be used (see note below).\n",
      "     |          default: 'regression' for LGBMRegressor, 'binary' or 'multiclass' for LGBMClassifier, 'lambdarank' for LGBMRanker.\n",
      "     |      min_split_gain : float, optional (default=0.)\n",
      "     |          Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
      "     |      min_child_weight : float, optional (default=1e-3)\n",
      "     |          Minimum sum of instance weight(hessian) needed in a child(leaf).\n",
      "     |      min_child_samples : int, optional (default=20)\n",
      "     |          Minimum number of data need in a child(leaf).\n",
      "     |      subsample : float, optional (default=1.)\n",
      "     |          Subsample ratio of the training instance.\n",
      "     |      subsample_freq : int, optional (default=1)\n",
      "     |          Frequence of subsample, <=0 means no enable.\n",
      "     |      colsample_bytree : float, optional (default=1.)\n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |      reg_alpha : float, optional (default=0.)\n",
      "     |          L1 regularization term on weights.\n",
      "     |      reg_lambda : float, optional (default=0.)\n",
      "     |          L2 regularization term on weights.\n",
      "     |      random_state : int or None, optional (default=None)\n",
      "     |          Random number seed.\n",
      "     |          Will use default seeds in c++ code if set to None.\n",
      "     |      n_jobs : int, optional (default=-1)\n",
      "     |          Number of parallel threads.\n",
      "     |      silent : bool, optional (default=True)\n",
      "     |          Whether to print messages while running boosting.\n",
      "     |      **kwargs : other parameters\n",
      "     |          Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.\n",
      "     |      \n",
      "     |          Note\n",
      "     |          ----\n",
      "     |          \\*\\*kwargs is not supported in sklearn, it may cause unexpected issues.\n",
      "     |      \n",
      "     |      Attributes\n",
      "     |      ----------\n",
      "     |      n_features_ : int\n",
      "     |          The number of features of fitted model.\n",
      "     |      classes_ : array of shape = [n_classes]\n",
      "     |          The class label array (only for classification problem).\n",
      "     |      n_classes_ : int\n",
      "     |          The number of classes (only for classification problem).\n",
      "     |      best_score_ : dict or None\n",
      "     |          The best score of fitted model.\n",
      "     |      best_iteration_ : int or None\n",
      "     |          The best iteration of fitted model if ``early_stopping_rounds`` has been specified.\n",
      "     |      objective_ : string or callable\n",
      "     |          The concrete objective used while fitting this model.\n",
      "     |      booster_ : Booster\n",
      "     |          The underlying Booster of this model.\n",
      "     |      evals_result_ : dict or None\n",
      "     |          The evaluation results if ``early_stopping_rounds`` has been specified.\n",
      "     |      feature_importances_ : array of shape = [n_features]\n",
      "     |          The feature importances (the higher, the more important the feature).\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      A custom objective function can be provided for the ``objective``\n",
      "     |      parameter. In this case, it should have the signature\n",
      "     |      ``objective(y_true, y_pred) -> grad, hess`` or\n",
      "     |      ``objective(y_true, y_pred, group) -> grad, hess``:\n",
      "     |      \n",
      "     |          y_true: array-like of shape = [n_samples]\n",
      "     |              The target values.\n",
      "     |          y_pred: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The predicted values.\n",
      "     |          group: array-like\n",
      "     |              Group/query data, used for ranking task.\n",
      "     |          grad: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the gradient for each sample point.\n",
      "     |          hess: array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)\n",
      "     |              The value of the second derivative for each sample point.\n",
      "     |      \n",
      "     |      For multi-class task, the y_pred is group by class_id first, then group by row_id.\n",
      "     |      If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]\n",
      "     |      and you should group grad and hess in this way as well.\n",
      "     |  \n",
      "     |  apply(self, X, num_iteration=0)\n",
      "     |      Return the predicted leaf every tree for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array-like of shape = [n_samples, n_trees]\n",
      "     |          The predicted leaf every tree for each sample.\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : boolean, optional\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  predict(self, X, raw_score=False, num_iteration=0)\n",
      "     |      Return the predicted value for each sample.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      raw_score : bool, optional (default=False)\n",
      "     |          Whether to predict raw scores.\n",
      "     |      num_iteration : int, optional (default=0)\n",
      "     |          Limit number of iterations in the prediction; defaults to 0 (use all trees).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      predicted_result : array-like of shape = [n_samples] or shape = [n_samples, n_classes]\n",
      "     |          The predicted values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from LGBMModel:\n",
      "     |  \n",
      "     |  best_iteration_\n",
      "     |      Get the best iteration of fitted model.\n",
      "     |  \n",
      "     |  best_score_\n",
      "     |      Get the best score of fitted model.\n",
      "     |  \n",
      "     |  booster_\n",
      "     |      Get the underlying lightgbm Booster of this model.\n",
      "     |  \n",
      "     |  evals_result_\n",
      "     |      Get the evaluation results.\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Get feature importances.\n",
      "     |      \n",
      "     |      Note\n",
      "     |      ----\n",
      "     |      Feature importance in sklearn interface used to normalize to 1,\n",
      "     |      it's deprecated after 2.0.4 and same as Booster.feature_importance() now.\n",
      "     |  \n",
      "     |  n_features_\n",
      "     |      Get the number of features of fitted model.\n",
      "     |  \n",
      "     |  objective_\n",
      "     |      Get the concrete objective used while fitting this model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Returns the coefficient of determination R^2 of the prediction.\n",
      "     |      \n",
      "     |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      "     |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      "     |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always\n",
      "     |      predicts the expected value of y, disregarding the input features,\n",
      "     |      would get a R^2 score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape = (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      "     |          True values for X.\n",
      "     |      \n",
      "     |      sample_weight : array-like, shape = [n_samples], optional\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          R^2 of self.predict(X) wrt. y.\n",
      "\n",
      "FUNCTIONS\n",
      "    create_tree_digraph(booster, tree_index=0, show_info=None, name=None, comment=None, filename=None, directory=None, format=None, engine=None, encoding=None, graph_attr=None, node_attr=None, edge_attr=None, body=None, strict=False)\n",
      "        Create a digraph representation of specified tree.\n",
      "        \n",
      "        Note\n",
      "        ----\n",
      "        For more information please visit\n",
      "        http://graphviz.readthedocs.io/en/stable/api.html#digraph.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster : Booster or LGBMModel\n",
      "            Booster or LGBMModel instance.\n",
      "        tree_index : int, optional (default=0)\n",
      "            The index of a target tree to convert.\n",
      "        show_info : list or None, optional (default=None)\n",
      "            What information should be showed on nodes.\n",
      "            Possible values of list items: 'split_gain', 'internal_value', 'internal_count', 'leaf_count'.\n",
      "        name : string or None, optional (default=None)\n",
      "            Graph name used in the source code.\n",
      "        comment : string or None, optional (default=None)\n",
      "            Comment added to the first line of the source.\n",
      "        filename : string or None, optional (default=None)\n",
      "            Filename for saving the source.\n",
      "            If None, ``name`` + '.gv' is used.\n",
      "        directory : string or None, optional (default=None)\n",
      "            (Sub)directory for source saving and rendering.\n",
      "        format : string or None, optional (default=None)\n",
      "            Rendering output format ('pdf', 'png', ...).\n",
      "        engine : string or None, optional (default=None)\n",
      "            Layout command used ('dot', 'neato', ...).\n",
      "        encoding : string or None, optional (default=None)\n",
      "            Encoding for saving the source.\n",
      "        graph_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for the graph.\n",
      "        node_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for all nodes.\n",
      "        edge_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for all edges.\n",
      "        body : list of strings or None, optional (default=None)\n",
      "            Lines to add to the graph body.\n",
      "        strict : bool, optional (default=False)\n",
      "            Whether rendering should merge multi-edges.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        graph : graphviz.Digraph\n",
      "            The digraph representation of specified tree.\n",
      "    \n",
      "    cv(params, train_set, num_boost_round=10, folds=None, nfold=5, stratified=True, shuffle=True, metrics=None, fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', early_stopping_rounds=None, fpreproc=None, verbose_eval=None, show_stdv=True, seed=0, callbacks=None)\n",
      "        Perform the cross-validation with given paramaters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        params : dict\n",
      "            Parameters for Booster.\n",
      "        train_set : Dataset\n",
      "            Data to be trained on.\n",
      "        num_boost_round : int, optional (default=10)\n",
      "            Number of boosting iterations.\n",
      "        folds : a generator or iterator of (train_idx, test_idx) tuples or None, optional (default=None)\n",
      "            The train and test indices for the each fold.\n",
      "            This argument has highest priority over other data split arguments.\n",
      "        nfold : int, optional (default=5)\n",
      "            Number of folds in CV.\n",
      "        stratified : bool, optional (default=True)\n",
      "            Whether to perform stratified sampling.\n",
      "        shuffle: bool, optional (default=True)\n",
      "            Whether to shuffle before splitting data.\n",
      "        metrics : string, list of strings or None, optional (default=None)\n",
      "            Evaluation metrics to be monitored while CV.\n",
      "            If not None, the metric in ``params`` will be overridden.\n",
      "        fobj : callable or None, optional (default=None)\n",
      "            Custom objective function.\n",
      "        feval : callable or None, optional (default=None)\n",
      "            Custom evaluation function.\n",
      "        init_model : string or None, optional (default=None)\n",
      "            Filename of LightGBM model or Booster instance used for continue training.\n",
      "        feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "            Feature names.\n",
      "            If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "        categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "            Categorical features.\n",
      "            If list of int, interpreted as indices.\n",
      "            If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "            If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "        early_stopping_rounds: int or None, optional (default=None)\n",
      "            Activates early stopping. CV error needs to decrease at least\n",
      "            every ``early_stopping_rounds`` round(s) to continue.\n",
      "            Last entry in evaluation history is the one from best iteration.\n",
      "        fpreproc : callable or None, optional (default=None)\n",
      "            Preprocessing function that takes (dtrain, dtest, params)\n",
      "            and returns transformed versions of those.\n",
      "        verbose_eval : bool, int, or None, optional (default=None)\n",
      "            Whether to display the progress.\n",
      "            If None, progress will be displayed when np.ndarray is returned.\n",
      "            If True, progress will be displayed at every boosting stage.\n",
      "            If int, progress will be displayed at every given ``verbose_eval`` boosting stage.\n",
      "        show_stdv : bool, optional (default=True)\n",
      "            Whether to display the standard deviation in progress.\n",
      "            Results are not affected by this parameter, and always contains std.\n",
      "        seed : int, optional (default=0)\n",
      "            Seed used to generate the folds (passed to numpy.random.seed).\n",
      "        callbacks : list of callables or None, optional (default=None)\n",
      "            List of callback functions that are applied at each iteration.\n",
      "            See Callbacks in Python API for more information.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        eval_hist : dict\n",
      "            Evaluation history.\n",
      "            The dictionary has the following format:\n",
      "            {'metric1-mean': [values], 'metric1-stdv': [values],\n",
      "            'metric2-mean': [values], 'metric1-stdv': [values],\n",
      "            ...}.\n",
      "    \n",
      "    early_stopping(stopping_rounds, verbose=True)\n",
      "        Create a callback that activates early stopping.\n",
      "        \n",
      "        Note\n",
      "        ----\n",
      "        Activates early stopping.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        stopping_rounds : int\n",
      "           The possible number of rounds without the trend occurrence.\n",
      "        \n",
      "        verbose : bool, optional (default=True)\n",
      "            Whether to print message with early stopping information.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        callback : function\n",
      "            The callback that activates early stopping.\n",
      "    \n",
      "    plot_importance(booster, ax=None, height=0.2, xlim=None, ylim=None, title='Feature importance', xlabel='Feature importance', ylabel='Features', importance_type='split', max_num_features=None, ignore_zero=True, figsize=None, grid=True, **kwargs)\n",
      "        Plot model's feature importances.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster : Booster or LGBMModel\n",
      "            Booster or LGBMModel instance which feature importance should be plotted.\n",
      "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
      "            Target axes instance.\n",
      "            If None, new figure and axes will be created.\n",
      "        height : float, optional (default=0.2)\n",
      "            Bar height, passed to ``ax.barh()``.\n",
      "        xlim : tuple of 2 elements or None, optional (default=None)\n",
      "            Tuple passed to ``ax.xlim()``.\n",
      "        ylim : tuple of 2 elements or None, optional (default=None)\n",
      "            Tuple passed to ``ax.ylim()``.\n",
      "        title : string or None, optional (default=\"Feature importance\")\n",
      "            Axes title.\n",
      "            If None, title is disabled.\n",
      "        xlabel : string or None, optional (default=\"Feature importance\")\n",
      "            X-axis title label.\n",
      "            If None, title is disabled.\n",
      "        ylabel : string or None, optional (default=\"Features\")\n",
      "            Y-axis title label.\n",
      "            If None, title is disabled.\n",
      "        importance_type : string, optional (default=\"split\")\n",
      "            How the importance is calculated.\n",
      "            If \"split\", result contains numbers of times the feature is used in a model.\n",
      "            If \"gain\", result contains total gains of splits which use the feature.\n",
      "        max_num_features : int or None, optional (default=None)\n",
      "            Max number of top features displayed on plot.\n",
      "            If None or <1, all features will be displayed.\n",
      "        ignore_zero : bool, optional (default=True)\n",
      "            Whether to ignore features with zero importance.\n",
      "        figsize : tuple of 2 elements or None, optional (default=None)\n",
      "            Figure size.\n",
      "        grid : bool, optional (default=True)\n",
      "            Whether to add a grid for axes.\n",
      "        **kwargs : other parameters\n",
      "            Other parameters passed to ``ax.barh()``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ax : matplotlib.axes.Axes\n",
      "            The plot with model's feature importances.\n",
      "    \n",
      "    plot_metric(booster, metric=None, dataset_names=None, ax=None, xlim=None, ylim=None, title='Metric during training', xlabel='Iterations', ylabel='auto', figsize=None, grid=True)\n",
      "        Plot one metric during training.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster : dict or LGBMModel\n",
      "            Dictionary returned from ``lightgbm.train()`` or LGBMModel instance.\n",
      "        metric : string or None, optional (default=None)\n",
      "            The metric name to plot.\n",
      "            Only one metric supported because different metrics have various scales.\n",
      "            If None, first metric picked from dictionary (according to hashcode).\n",
      "        dataset_names : list of strings or None, optional (default=None)\n",
      "            List of the dataset names which are used to calculate metric to plot.\n",
      "            If None, all datasets are used.\n",
      "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
      "            Target axes instance.\n",
      "            If None, new figure and axes will be created.\n",
      "        xlim : tuple of 2 elements or None, optional (default=None)\n",
      "            Tuple passed to ``ax.xlim()``.\n",
      "        ylim : tuple of 2 elements or None, optional (default=None)\n",
      "            Tuple passed to ``ax.ylim()``.\n",
      "        title : string or None, optional (default=\"Metric during training\")\n",
      "            Axes title.\n",
      "            If None, title is disabled.\n",
      "        xlabel : string or None, optional (default=\"Iterations\")\n",
      "            X-axis title label.\n",
      "            If None, title is disabled.\n",
      "        ylabel : string or None, optional (default=\"auto\")\n",
      "            Y-axis title label.\n",
      "            If 'auto', metric name is used.\n",
      "            If None, title is disabled.\n",
      "        figsize : tuple of 2 elements or None, optional (default=None)\n",
      "            Figure size.\n",
      "        grid : bool, optional (default=True)\n",
      "            Whether to add a grid for axes.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ax : matplotlib.axes.Axes\n",
      "            The plot with metric's history over the training.\n",
      "    \n",
      "    plot_tree(booster, ax=None, tree_index=0, figsize=None, graph_attr=None, node_attr=None, edge_attr=None, show_info=None)\n",
      "        Plot specified tree.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster : Booster or LGBMModel\n",
      "            Booster or LGBMModel instance to be plotted.\n",
      "        ax : matplotlib.axes.Axes or None, optional (default=None)\n",
      "            Target axes instance.\n",
      "            If None, new figure and axes will be created.\n",
      "        tree_index : int, optional (default=0)\n",
      "            The index of a target tree to plot.\n",
      "        figsize : tuple of 2 elements or None, optional (default=None)\n",
      "            Figure size.\n",
      "        graph_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for the graph.\n",
      "        node_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for all nodes.\n",
      "        edge_attr : dict or None, optional (default=None)\n",
      "            Mapping of (attribute, value) pairs set for all edges.\n",
      "        show_info : list or None, optional (default=None)\n",
      "            What information should be showed on nodes.\n",
      "            Possible values of list items: 'split_gain', 'internal_value', 'internal_count', 'leaf_count'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ax : matplotlib.axes.Axes\n",
      "            The plot with single tree.\n",
      "    \n",
      "    print_evaluation(period=1, show_stdv=True)\n",
      "        Create a callback that prints the evaluation results.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        period : int, optional (default=1)\n",
      "            The period to print the evaluation results.\n",
      "        show_stdv : bool, optional (default=True)\n",
      "            Whether to show stdv (if provided).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        callback : function\n",
      "            The callback that prints the evaluation results every ``period`` iteration(s).\n",
      "    \n",
      "    record_evaluation(eval_result)\n",
      "        Create a callback that records the evaluation history into ``eval_result``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        eval_result : dict\n",
      "           A dictionary to store the evaluation results.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        callback : function\n",
      "            The callback that records the evaluation history into the passed dictionary.\n",
      "    \n",
      "    reset_parameter(**kwargs)\n",
      "        Create a callback that resets the parameter after the first iteration.\n",
      "        \n",
      "        Note\n",
      "        ----\n",
      "        The initial parameter will still take in-effect on first iteration.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        **kwargs: value should be list or function\n",
      "            List of parameters for each boosting round\n",
      "            or a customized function that calculates the parameter in terms of\n",
      "            current number of round (e.g. yields learning rate decay).\n",
      "            If list lst, parameter = lst[current_round].\n",
      "            If function func, parameter = func(current_round).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        callback : function\n",
      "            The callback that resets the parameter after the first iteration.\n",
      "    \n",
      "    train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', early_stopping_rounds=None, evals_result=None, verbose_eval=True, learning_rates=None, keep_training_booster=False, callbacks=None)\n",
      "        Perform the training with given parameters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        params : dict\n",
      "            Parameters for training.\n",
      "        train_set : Dataset\n",
      "            Data to be trained.\n",
      "        num_boost_round: int, optional (default=100)\n",
      "            Number of boosting iterations.\n",
      "        valid_sets: list of Datasets or None, optional (default=None)\n",
      "            List of data to be evaluated during training.\n",
      "        valid_names: list of string or None, optional (default=None)\n",
      "            Names of ``valid_sets``.\n",
      "        fobj : callable or None, optional (default=None)\n",
      "            Customized objective function.\n",
      "        feval : callable or None, optional (default=None)\n",
      "            Customized evaluation function.\n",
      "            Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
      "        init_model : string or None, optional (default=None)\n",
      "            Filename of LightGBM model or Booster instance used for continue training.\n",
      "        feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "            Feature names.\n",
      "            If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "        categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "            Categorical features.\n",
      "            If list of int, interpreted as indices.\n",
      "            If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "            If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "        early_stopping_rounds: int or None, optional (default=None)\n",
      "            Activates early stopping. The model will train until the validation score stops improving.\n",
      "            Requires at least one validation data and one metric. If there's more than one, will check all of them.\n",
      "            If early stopping occurs, the model will add ``best_iteration`` field.\n",
      "        evals_result: dict or None, optional (default=None)\n",
      "            This dictionary used to store all evaluation results of all the items in ``valid_sets``.\n",
      "        \n",
      "            Example\n",
      "            -------\n",
      "            With a ``valid_sets`` = [valid_set, train_set],\n",
      "            ``valid_names`` = ['eval', 'train']\n",
      "            and a ``params`` = ('metric':'logloss')\n",
      "            returns: {'train': {'logloss': ['0.48253', '0.35953', ...]},\n",
      "            'eval': {'logloss': ['0.480385', '0.357756', ...]}}.\n",
      "        verbose_eval : bool or int, optional (default=True)\n",
      "            Requires at least one validation data.\n",
      "            If True, the eval metric on the valid set is printed at each boosting stage.\n",
      "            If int, the eval metric on the valid set is printed at every ``verbose_eval`` boosting stage.\n",
      "            The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "        \n",
      "            Example\n",
      "            -------\n",
      "            With ``verbose_eval`` = 4 and at least one item in evals,\n",
      "            an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "        learning_rates: list, callable or None, optional (default=None)\n",
      "            List of learning rates for each boosting round\n",
      "            or a customized function that calculates ``learning_rate``\n",
      "            in terms of current number of round (e.g. yields learning rate decay).\n",
      "        keep_training_booster : bool, optional (default=False)\n",
      "            Whether the returned Booster will be used to keep training.\n",
      "            If False, the returned value will be converted into _InnerPredictor before returning.\n",
      "            You can still use _InnerPredictor as ``init_model`` for future continue training.\n",
      "        callbacks : list of callables or None, optional (default=None)\n",
      "            List of callback functions that are applied at each iteration.\n",
      "            See Callbacks in Python API for more information.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        booster : Booster\n",
      "            The trained Booster model.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Dataset', 'Booster', 'train', 'cv', 'LGBMModel', 'LGBMRegr...\n",
      "    __warningregistry__ = {'version': 384, (\"unclosed file <_io.TextIOWrap...\n",
      "\n",
      "VERSION\n",
      "    2.0.11\n",
      "\n",
      "FILE\n",
      "    /home/masakick/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=15,n_estimators=120)\n",
    "forest.fit(x_train,y_train)\n",
    "svm = SVC(probability=True,C=10,gamma=0.05)\n",
    "svm.fit(x_train,y_train)\n",
    "lr = LogisticRegression(C=1,penalty=\"l2\")\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_clf(x_train,y_train,*clfs):\n",
    "    if len(clfs) > 1:\n",
    "        clf_ls = []\n",
    "        for clf in clfs:\n",
    "            clf_ls.append((str(clf),clf))\n",
    "        new_clf = VotingClassifier(estimators=clf_ls,n_jobs=-1,voting=\"soft\")\n",
    "    else:\n",
    "        new_clf = clfs[0]\n",
    "    new_clf.fit(x_train,y_train)\n",
    "    print(accuracy_score(y_true=y_train,y_pred=new_clf.predict(x_train)))\n",
    "    print(accuracy_score(y_true=y_test,y_pred=new_clf.predict(x_test)))\n",
    "    return new_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15000 candidates, totalling 150000 fits\n"
     ]
    }
   ],
   "source": [
    "new_clf = mk_clf(x_train,y_train,gs_lgb,gs_lr,gs_svc_lin,gs_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858208955224\n",
      "0.84328358209\n",
      "0.832089552239\n",
      "0.847014925373\n",
      "0.85447761194\n",
      "0.850746268657\n",
      "0.839552238806\n",
      "0.832089552239\n",
      "0.832089552239\n",
      "0.80223880597\n",
      "0.828358208955\n",
      "0.824626865672\n",
      "0.85447761194\n",
      "0.839552238806\n",
      "0.828358208955\n",
      "0.850746268657\n",
      "0.832089552239\n",
      "0.820895522388\n",
      "0.847014925373\n",
      "0.828358208955\n",
      "accuracy: 0.837313432836 +/- 0.0134742314069\n"
     ]
    }
   ],
   "source": [
    "score_ls = []\n",
    "for i in range(20):\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "    score_ls.append(accuracy_score(y_test,new_clf.predict(x_test)))\n",
    "    print(accuracy_score(y_test,new_clf.predict(x_test)))\n",
    "print(\"accuracy:\",np.mean(score_ls),\"+/-\",np.std(score_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ化　svm 0.81887677175 +/- 0.0478131357673\n",
    "非カテゴリ化　lr,svm 0.826843536168 +/- 0.059019734912\n",
    "全部　0.820391923265 +/- 0.0495593393716\n",
    "svm 0.822004826491 +/- 0.0526570211202\n",
    "forest,svm 0.812280058651 +/- 0.0453577598613\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847512038523\n",
      "0.805970149254\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true=y_train,y_pred=new_clf.predict(x_train)))\n",
    "print(accuracy_score(y_true=y_test,y_pred=new_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77777778  0.80952381  0.80952381  0.85714286  0.84126984  0.77777778\n",
      "  0.83870968  0.75409836  0.72131148  0.83606557]\n",
      "0.802320096027 +/- 0.0414508706975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "#new_clf2 = VotingClassifier(estimators=[(\"gs\",gs),(\"gs1\",gs1),(\"gs2\",gs2)],n_jobs=-1,voting=\"soft\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator=new_forest,X=x_train,y=y_train,cv=10,n_jobs=-1,verbose=1)\n",
    "print(scores)\n",
    "print(np.mean(scores),\"+/-\",np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80223880597\n",
      "0.80223880597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1.0, lambda_l1=0.1,\n",
       "        lambda_l2=0.1, learning_rate=0.3, max_depth=30,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.5,\n",
       "        n_estimators=10, n_jobs=-1, num_leaves=31, objective='binary',\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=0.8, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = gs.best_estimator_\n",
    "print(accuracy_score(y_test,gs.predict(x_test)))\n",
    "print(accuracy_score(y_test,lgb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass  Name  Sex   Age  SibSp  Parch   Ticket     Fare Cabin  \\\n",
      "0          892       3     1    1  34.5      0      0   330911   7.8292   NaN   \n",
      "1          893       3     4    0  47.0      1      0   363272   7.0000   NaN   \n",
      "2          894       2     1    1  62.0      0      0   240276   9.6875   NaN   \n",
      "3          895       3     1    1  27.0      0      0   315154   8.6625   NaN   \n",
      "4          896       3     4    0  22.0      1      1  3101298  12.2875   NaN   \n",
      "\n",
      "   Embarked  child SUM  isalone  \n",
      "0         2      0   0        1  \n",
      "1         1      0   1        0  \n",
      "2         2      0   0        1  \n",
      "3         1      0   0        1  \n",
      "4         1      0   2        0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/home/masakick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>isalone</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Age  Fare  isalone  Embarked  SUM\n",
       "0       3.0  1.0  2.0   0.0      1.0       2.0  0.0\n",
       "1       3.0  0.0  2.0   0.0      0.0       1.0  1.0\n",
       "2       2.0  1.0  3.0   1.0      1.0       2.0  0.0\n",
       "3       3.0  1.0  1.0   1.0      1.0       1.0  0.0\n",
       "4       3.0  0.0  1.0   1.0      0.0       1.0  2.0\n",
       "5       3.0  1.0  0.0   1.0      1.0       1.0  0.0\n",
       "6       3.0  0.0  1.0   0.0      1.0       2.0  0.0\n",
       "7       2.0  1.0  1.0   2.0      0.0       1.0  2.0\n",
       "8       3.0  0.0  1.0   0.0      1.0       3.0  0.0\n",
       "9       3.0  1.0  1.0   2.0      0.0       1.0  2.0\n",
       "10      3.0  1.0  2.0   0.0      1.0       1.0  0.0\n",
       "11      1.0  1.0  2.0   2.0      1.0       1.0  0.0\n",
       "12      1.0  0.0  1.0   3.0      0.0       1.0  1.0\n",
       "13      2.0  1.0  3.0   2.0      0.0       1.0  1.0\n",
       "14      1.0  0.0  2.0   3.0      0.0       1.0  1.0\n",
       "15      2.0  0.0  1.0   2.0      0.0       3.0  1.0\n",
       "16      2.0  1.0  2.0   1.0      1.0       2.0  0.0\n",
       "17      3.0  1.0  1.0   0.0      1.0       3.0  0.0\n",
       "18      3.0  0.0  1.0   1.0      0.0       1.0  1.0\n",
       "19      3.0  0.0  2.0   0.0      1.0       3.0  0.0\n",
       "20      1.0  1.0  3.0   3.0      0.0       3.0  1.0\n",
       "21      3.0  1.0  0.0   0.0      0.0       1.0  1.0\n",
       "22      1.0  0.0  2.0   3.0      1.0       1.0  0.0\n",
       "23      1.0  1.0  1.0   3.0      0.0       3.0  1.0\n",
       "24      1.0  0.0  2.0   3.0      0.0       3.0  4.0\n",
       "25      3.0  1.0  3.0   2.0      0.0       1.0  1.0\n",
       "26      1.0  0.0  1.0   3.0      0.0       3.0  1.0\n",
       "27      3.0  1.0  1.0   0.0      1.0       3.0  0.0\n",
       "28      1.0  1.0  2.0   2.0      1.0       1.0  0.0\n",
       "29      3.0  1.0  2.0   2.0      0.0       3.0  2.0\n",
       "..      ...  ...  ...   ...      ...       ...  ...\n",
       "388     3.0  1.0  1.0   0.0      1.0       2.0  0.0\n",
       "389     3.0  1.0  0.0   2.0      0.0       1.0  4.0\n",
       "390     1.0  1.0  1.0   3.0      1.0       1.0  0.0\n",
       "391     1.0  0.0  3.0   3.0      0.0       1.0  1.0\n",
       "392     3.0  1.0  0.0   2.0      0.0       1.0  2.0\n",
       "393     2.0  1.0  2.0   1.0      1.0       1.0  0.0\n",
       "394     3.0  1.0  1.0   2.0      0.0       1.0  4.0\n",
       "395     1.0  0.0  1.0   3.0      0.0       1.0  1.0\n",
       "396     3.0  1.0  1.0   0.0      1.0       2.0  0.0\n",
       "397     1.0  0.0  2.0   3.0      0.0       3.0  2.0\n",
       "398     3.0  1.0  1.0   0.0      1.0       1.0  0.0\n",
       "399     3.0  1.0  1.0   0.0      1.0       2.0  0.0\n",
       "400     1.0  0.0  1.0   3.0      1.0       1.0  0.0\n",
       "401     2.0  1.0  2.0   2.0      0.0       1.0  1.0\n",
       "402     1.0  0.0  1.0   3.0      0.0       3.0  1.0\n",
       "403     1.0  1.0  1.0   3.0      1.0       1.0  0.0\n",
       "404     1.0  1.0  2.0   2.0      0.0       3.0  1.0\n",
       "405     2.0  1.0  1.0   1.0      1.0       3.0  0.0\n",
       "406     2.0  1.0  1.0   1.0      0.0       1.0  1.0\n",
       "407     1.0  1.0  3.0   3.0      0.0       3.0  2.0\n",
       "408     3.0  0.0  1.0   0.0      1.0       2.0  0.0\n",
       "409     3.0  0.0  0.0   1.0      0.0       1.0  2.0\n",
       "410     3.0  0.0  1.0   0.0      1.0       2.0  0.0\n",
       "411     1.0  0.0  2.0   3.0      0.0       2.0  1.0\n",
       "412     3.0  0.0  1.0   0.0      1.0       1.0  0.0\n",
       "413     3.0  1.0  2.0   1.0      1.0       1.0  0.0\n",
       "414     1.0  0.0  2.0   3.0      1.0       3.0  0.0\n",
       "415     3.0  1.0  2.0   0.0      1.0       1.0  0.0\n",
       "416     3.0  1.0  2.0   1.0      1.0       1.0  0.0\n",
       "417     3.0  1.0  0.0   2.0      0.0       3.0  2.0\n",
       "\n",
       "[418 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_csv(\"test.csv\")\n",
    "#df3.columns=[\"PassengerId\",\"Pclass\",\"Name\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\",\"Cabin\",\"Embarked\"]\n",
    "#df3=df3.ix[1:,:]\n",
    "\n",
    "#df3[\"Cabin\"] = cabin_cha(df3[\"Cabin\"].values)\n",
    "#s = pd.get_dummies(df3[\"Cabin\"])\n",
    "#df3 = pd.merge(df3,s,left_index=True, right_index=True)\n",
    "\n",
    "df3[\"child\"]=df3[\"Age\"].apply(lambda x:1 if x < 15 else 0)\n",
    "df3[\"Embarked\"]=df3[\"Embarked\"].map({\"S\":1,\"Q\":2,\"C\":3})\n",
    "\n",
    "df3[\"Name\"] = df3[\"Name\"].map(miss_only)\n",
    "df3[\"Name\"] = df3[\"Name\"].map(mr_to_num)\n",
    "\n",
    "df4 = df3\n",
    "\n",
    "sums=sum_maker(df4[\"SibSp\"].values,df4[\"Parch\"].values)\n",
    "sums=pd.DataFrame(sums.values,index=range(418),columns=[\"SUM\"])\n",
    "df4=pd.merge(df4,sums,right_index=True,left_index=True)\n",
    "\n",
    "df4[\"isalone\"] = df4[\"SUM\"].apply(lambda x:1 if x == 0 else 0)\n",
    "#namesums=name(df4[\"Name\"])\n",
    "#df4=pd.merge(df4,namesums,right_index=True,left_index=True)\n",
    "\n",
    "df4[\"Sex\"]=le.transform(df4[\"Sex\"])\n",
    "\n",
    "\n",
    "#s1=pd.get_dummies(df4[\"Embarked\"])\n",
    "#df4=pd.merge(df4,s1,right_index=True,left_index=True)\n",
    "print(df4.head())\n",
    "df4=df4.ix[:,a]\n",
    "\n",
    "df4[\"Embarked\"].fillna(\"S\")\n",
    "df4[df4[\"Name\"]==1]=imr1.transform(df4[df4[\"Name\"]==1])\n",
    "df4[df4[\"Name\"]==2]=imr2.transform(df4[df4[\"Name\"]==2])\n",
    "df4[df4[\"Name\"]==3]=imr3.transform(df4[df4[\"Name\"]==3])\n",
    "df4[df4[\"Name\"]==4]=imr4.transform(df4[df4[\"Name\"]==4])\n",
    "df4 = pd.DataFrame(imr.transform(df4),columns=a)\n",
    "\n",
    "df4.ix[df4[\"Age\"] < 16.336,\"Age\"] = 0\n",
    "df4.ix[(df4[\"Age\"] < 32.252) & (df4[\"Age\"] >= 16.336),\"Age\"] = 1\n",
    "df4.ix[(df4[\"Age\"] < 48.168) & (df4[\"Age\"] >= 32.252),\"Age\"] = 2\n",
    "df4.ix[(df4[\"Age\"] < 64.084) & (df4[\"Age\"] >= 48.168),\"Age\"] = 3\n",
    "df4.ix[df4[\"Age\"] >= 64.084,\"Age\"] = 4\n",
    "\n",
    "df4.ix[df4[\"Fare\"] < 7.91,\"Fare\"] = 0\n",
    "df4.ix[(df4[\"Fare\"] < 14.454) & (df4[\"Fare\"] >= 7.91),\"Fare\"] = 1\n",
    "df4.ix[(df4[\"Fare\"] < 31) & (df4[\"Fare\"] >= 14.454),\"Fare\"] = 2\n",
    "df4.ix[df4[\"Fare\"] >= 31,\"Fare\"] = 3\n",
    "\"\"\"\n",
    "df4[\"Fare\"] = sc1.transform(df4[\"Fare\"].reshape(len(df4[\"Fare\"].values),1))\n",
    "#df4[\"SibSp\"] = sc2.transform(df4[\"SibSp\"].reshape(len(df4[\"Fare\"].values),1))\n",
    "#df4[\"Parch\"] = sc3.transform(df4[\"Parch\"])\n",
    "df4[\"Age\"] = sc4.transform(df4[\"Age\"].reshape(len(df4[\"Fare\"].values),1))\n",
    "\"\"\"\n",
    "#pd.DataFrame(a)\n",
    "x_te=df4.ix[:,b] #.astype(int)\n",
    "#x_te.columns=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"miss\",\"mr\",\"mrs\",\"master\",\"SUM\",\"C\",\"Q\",\"S\"]\n",
    "x_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Sex', 'Age', 'Fare', 'isalone', 'Embarked', 'SUM'], dtype='object')\n",
      "Index(['Pclass', 'Sex', 'Age', 'Fare', 'isalone', 'Embarked', 'SUM'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_train.columns)\n",
    "print(x_te.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex  Age  Fare  isalone  Embarked  SUM\n",
      "300     3.0  0.0  1.0   0.0      1.0       2.0  0.0\n",
      "185     1.0  1.0  2.0   3.0      1.0       1.0  0.0\n",
      "255     3.0  0.0  1.0   2.0      0.0       3.0  2.0\n",
      "214     3.0  1.0  2.0   0.0      0.0       2.0  1.0\n",
      "22      3.0  0.0  0.0   1.0      1.0       2.0  0.0\n",
      "   Pclass  Sex  Age  Fare  isalone  Embarked  SUM\n",
      "0     3.0  1.0  2.0   0.0      1.0       2.0  0.0\n",
      "1     3.0  0.0  2.0   0.0      0.0       1.0  1.0\n",
      "2     2.0  1.0  3.0   1.0      1.0       2.0  0.0\n",
      "3     3.0  1.0  1.0   1.0      1.0       1.0  0.0\n",
      "4     3.0  0.0  1.0   1.0      0.0       1.0  2.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(x_te.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "Fare        0\n",
      "isalone     0\n",
      "Embarked    0\n",
      "SUM         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_te.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=new_clf.predict(x_te)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_data = zip(df3.ix[:,0].astype(int), y_pred.astype(int))\n",
    "predict_data = list(zip_data)\n",
    "import csv\n",
    "with open(\"predcit_result_data.csv\",\"w\") as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n')\n",
    "    writer.writerow([\"PassengerId\", \"Survived\"])\n",
    "    for pid, survived in zip(df3.ix[:,0].astype(int), y_pred.astype(int)):\n",
    "        writer.writerow([pid, survived])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25901993240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "training_sizes, train_scores, test_scores = \\\n",
    "    learning_curve(new_clf,x,y,scoring=\"accuracy\", train_sizes = [0.6,0.7,0.8,0.9,1.0],n_jobs=-1)\n",
    "plt.plot(training_sizes,train_scores.mean(axis=1),label=\"training_scores\")\n",
    "plt.plot(training_sizes,test_scores.mean(axis=1),label=\"test_scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "memo_df = pd.read_csv(\"test.csv\")\n",
    "print(memo_df.shape)\n",
    "print(memo_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch  \\\n",
      "Embarked                                                               \n",
      "C               74820        93     317   95   4005.92     65     61   \n",
      "Q               32178        30     224   41    786.50     33     13   \n",
      "S              289496       217    1514  441  16312.75    368    266   \n",
      "\n",
      "                Fare  child  \n",
      "Embarked                     \n",
      "C         10072.2962     15  \n",
      "Q          1022.2543      4  \n",
      "S         17439.3988     59  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1f4a5d267b8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEUCAYAAADqcMl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4a53b89b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(df.groupby(\"Embarked\").sum())\n",
    "sns.set(style=\"ticks\")\n",
    "g = sns.factorplot(x=\"Embarked\",y=\"Survived\",kind=\"bar\",data=df,palette=\"muted\")\n",
    "g.despine(left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEUCAYAAADqcMl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFADWUCgArKFQAFjzP9O6p5snGtwfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4a531e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = sns.factorplot(x=\"Sex\",y=\"Survived\",kind=\"bar\",palette=\"muted\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEUCAYAAACyD1pgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHxFJh8FHRNJh8BGRdBh8RCSd/wOYDxC9+Q1U4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4a5d019e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = sns.factorplot(x=\"Sex\",y=\"Survived\",hue=\"child\",data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#print(len(df.ix[df[\"Embarked\"]==\"S\",\"Name\"].values))\n",
    "#print(len(df.ix[df[\"Embarked\"]==\"Q\",\"Name\"].values))\n",
    "#print(len(df.ix[df[\"Embarked\"]==\"C\",\"Name\"].values))\n",
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9618be9748>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8//xAHNL1o0hEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9618ba4da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.countplot(x=\"SibSP\",,data=df,kind=\"bar\")\n",
    "sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9618cd0240>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYCKiTAImIsokYCKiTAImIsr8HymYFFRBJ0v4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9618cd0358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(x=\"Parch\",y=\"Survived\",data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f961025a8d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkdTGgJHUxoCR1Ob/AxSjeDvF9LP/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f961025a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.factorplot(x=\"SUM\",y=\"Survived\",data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
